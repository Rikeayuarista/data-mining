{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Biodata \u00b6 Nama : Rike Ayu Arista NIM : 180411100088 Matakuliah : Penambangan Data 5-D Program Studi : Teknik Informatika Fakultas : Teknik Perguruan Tinggi : Universitas Trunojoyo Madura","title":"index"},{"location":"#welcome","text":"","title":"Welcome"},{"location":"#biodata","text":"Nama : Rike Ayu Arista NIM : 180411100088 Matakuliah : Penambangan Data 5-D Program Studi : Teknik Informatika Fakultas : Teknik Perguruan Tinggi : Universitas Trunojoyo Madura","title":"Biodata"},{"location":"DECISION TREE/","text":"DECISION TREE \u00b6 decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan. CARA MEMBUAT DECISION TREE \u00b6 \u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"Decision Tree"},{"location":"DECISION TREE/#decision-tree","text":"decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan.","title":"DECISION TREE"},{"location":"DECISION TREE/#cara-membuat-decision-tree","text":"\u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"CARA MEMBUAT DECISION TREE"},{"location":"Home/","text":"\u00b6 profil \u200b Nama : moh.imam wahyudi \u200b Nim : 180411100007 \u200b Prodi : Teknik Informatika","title":"Home"},{"location":"Monte Carlo (komnum)/","text":"Metode dan Simulasi Monte Carlo \u00b6 Metode Monte Carlo \u00b6 Metode Monte Carlo adalah algoritma kom put asi untuk mensimulasikan berbagai perilaku sistem fisika dan matematika. Penggunaan klasik metode ini adalah untuk mengevaluasi integral definit, terutama integral multidimensi dengan syarat dan batasan yang rumit. Metode ini sangat efisien dalam memecahkan persamaan diferensial integral medan radians. karena metode ini memerlukan pengulangan dan perhitungan yang amat kompleks, metode ini pada umumnya dilakukan menggunakan komputer dan memakai berbagai teknik simulasi komputer. Melihat dari cara kerjanya metode Monte Carlo merupakan metode yang memberikan segala kemungkinan nilai dari suatu variabel. Metode Monte Carlo merupakan metode yang memanfaatkan strong law of large number dalam melakukan perhitungan, artinya semakin banyak variabel acak yang digunakan akan semakin baik pula pendekatan nilai eksaknya Algoritma dan contoh Metode Monte Carlo \u00b6 Algotitma monte carlo adalah metode monte yang digunakan untuk menemukan solusi paroblem matematis (yang terdiri dari banyak variabel) yang susah dipecahkan, misallnya dengan kalkulis integral atau metode numerik lainnya. Probabilitas pelemparan coin Ganda Dari teori peluang akan muncul: MM \u00ce \u00bc MB atau BM \u00ce \u00bd BB \u00ce \u00bc Dengan metode Monte Carlo dapatkan tingkat ketelitian sampai 0.01 untuk menyelesaikan kasus tersebut\u2026. Untuk mendapatkan ketelitian sampai 0,01 maka harus dilakukan pelemparan sebanyak 1000 (N_total) kali. Dari hasil pelemparan catat keluarnya angka-angka: P(MM) = N(MM)/N_total P(MB) = N(MB)/N_total P(BB) = N(BB)/N_total Algoritma \u00b6 Bangkitkan nilai 0/1 sebanyak 1000 kali (N=1000) dengan cara: n1 =(int)rand()%2 dan n2 =(int)rand()%2 Klasifikasi Jika n1=0 dan n2=0, maka MM=MM+1 Jika n1=0 dan n2=1 atau n1=1 dan n2=0 maka MB=MB+1 Jika n1=1 dan n2=1, maka BB=BB+1 Hitung probabilitas MM dengan cara N(MM)/N dan probabilitas untuk nilai MB serta BB 2.Menghitung Nilai Integral dengan monte carlo Luas area dicari = yang berwarna atau daerah dibawah garis fungsi f(x) = 2x Dengan dasar pemikiran tersebut diperoleh suatu perbandingan: BIla kita melakukan pelemparan coin sebanyak N kali, dan coin jatuh di bawah garis f(x) =2x sebanyak M kali. Maka: Tugas Programing \u00b6 implemenasi metode carlo dalam python \u00b6 from scipy import random import numpy as np import matplotlib.pyplot as plt a = 0 b = 2 N = 2500 def func ( x ): return ( 4 - x ** 2 ) ** 0.5 area = [] for i in range ( N ): xrand = np . zeros ( N ) for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) integral = 0.0 for i in range ( N ): integral += func ( xrand [ i ]) jawab = ( b - a ) / float ( N ) * integral area . append ( jawab ) plt . title ( \"Hasil phi\" ) plt . hist ( area , bins = 30 , ec = 'black' ) plt . xlabel ( \"Area\" ) plt . show () hasil running \u00b6 from scipy import random import numpy as np a = - 1 b = 1 N = 100 xrand = np . zeros ( N ) yrand = np . zeros ( N ) zrand = np . zeros ( N ) integral = 0.0 for i in range ( 4 ): for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) for i in range ( len ( yrand )): yrand [ i ] = random . uniform ( a , b ) for i in range ( len ( zrand )): zrand [ i ] = random . uniform ( a , b ) def func ( x , y , z ): return ( x ** 2 ) + ( y ** 2 ) + ( z ** 2 ) for i in range ( N ): integral += func ( xrand [ i ], yrand [ i ], zrand [ i ]) jawab = ( b - a ) / float ( N ) * integral print ( \"jawab: \" , jawab ) hasil running \u00b6 jawab : 7.941487167529855","title":"Monte Carlo"},{"location":"Monte Carlo (komnum)/#metode-dan-simulasi-monte-carlo","text":"","title":"Metode dan Simulasi Monte Carlo"},{"location":"Monte Carlo (komnum)/#metode-monte-carlo","text":"Metode Monte Carlo adalah algoritma kom put asi untuk mensimulasikan berbagai perilaku sistem fisika dan matematika. Penggunaan klasik metode ini adalah untuk mengevaluasi integral definit, terutama integral multidimensi dengan syarat dan batasan yang rumit. Metode ini sangat efisien dalam memecahkan persamaan diferensial integral medan radians. karena metode ini memerlukan pengulangan dan perhitungan yang amat kompleks, metode ini pada umumnya dilakukan menggunakan komputer dan memakai berbagai teknik simulasi komputer. Melihat dari cara kerjanya metode Monte Carlo merupakan metode yang memberikan segala kemungkinan nilai dari suatu variabel. Metode Monte Carlo merupakan metode yang memanfaatkan strong law of large number dalam melakukan perhitungan, artinya semakin banyak variabel acak yang digunakan akan semakin baik pula pendekatan nilai eksaknya","title":"Metode  Monte Carlo"},{"location":"Monte Carlo (komnum)/#algoritma-dan-contoh-metode-monte-carlo","text":"Algotitma monte carlo adalah metode monte yang digunakan untuk menemukan solusi paroblem matematis (yang terdiri dari banyak variabel) yang susah dipecahkan, misallnya dengan kalkulis integral atau metode numerik lainnya. Probabilitas pelemparan coin Ganda Dari teori peluang akan muncul: MM \u00ce \u00bc MB atau BM \u00ce \u00bd BB \u00ce \u00bc Dengan metode Monte Carlo dapatkan tingkat ketelitian sampai 0.01 untuk menyelesaikan kasus tersebut\u2026. Untuk mendapatkan ketelitian sampai 0,01 maka harus dilakukan pelemparan sebanyak 1000 (N_total) kali. Dari hasil pelemparan catat keluarnya angka-angka: P(MM) = N(MM)/N_total P(MB) = N(MB)/N_total P(BB) = N(BB)/N_total","title":"Algoritma dan contoh Metode Monte Carlo"},{"location":"Monte Carlo (komnum)/#algoritma","text":"Bangkitkan nilai 0/1 sebanyak 1000 kali (N=1000) dengan cara: n1 =(int)rand()%2 dan n2 =(int)rand()%2 Klasifikasi Jika n1=0 dan n2=0, maka MM=MM+1 Jika n1=0 dan n2=1 atau n1=1 dan n2=0 maka MB=MB+1 Jika n1=1 dan n2=1, maka BB=BB+1 Hitung probabilitas MM dengan cara N(MM)/N dan probabilitas untuk nilai MB serta BB 2.Menghitung Nilai Integral dengan monte carlo Luas area dicari = yang berwarna atau daerah dibawah garis fungsi f(x) = 2x Dengan dasar pemikiran tersebut diperoleh suatu perbandingan: BIla kita melakukan pelemparan coin sebanyak N kali, dan coin jatuh di bawah garis f(x) =2x sebanyak M kali. Maka:","title":"Algoritma"},{"location":"Monte Carlo (komnum)/#tugas-programing","text":"","title":"Tugas Programing"},{"location":"Monte Carlo (komnum)/#implemenasi-metode-carlo-dalam-python","text":"from scipy import random import numpy as np import matplotlib.pyplot as plt a = 0 b = 2 N = 2500 def func ( x ): return ( 4 - x ** 2 ) ** 0.5 area = [] for i in range ( N ): xrand = np . zeros ( N ) for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) integral = 0.0 for i in range ( N ): integral += func ( xrand [ i ]) jawab = ( b - a ) / float ( N ) * integral area . append ( jawab ) plt . title ( \"Hasil phi\" ) plt . hist ( area , bins = 30 , ec = 'black' ) plt . xlabel ( \"Area\" ) plt . show ()","title":"implemenasi metode carlo dalam python"},{"location":"Monte Carlo (komnum)/#hasil-running","text":"from scipy import random import numpy as np a = - 1 b = 1 N = 100 xrand = np . zeros ( N ) yrand = np . zeros ( N ) zrand = np . zeros ( N ) integral = 0.0 for i in range ( 4 ): for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) for i in range ( len ( yrand )): yrand [ i ] = random . uniform ( a , b ) for i in range ( len ( zrand )): zrand [ i ] = random . uniform ( a , b ) def func ( x , y , z ): return ( x ** 2 ) + ( y ** 2 ) + ( z ** 2 ) for i in range ( N ): integral += func ( xrand [ i ], yrand [ i ], zrand [ i ]) jawab = ( b - a ) / float ( N ) * integral print ( \"jawab: \" , jawab )","title":"hasil running"},{"location":"Monte Carlo (komnum)/#hasil-running_1","text":"jawab : 7.941487167529855","title":"hasil running"},{"location":"Numerical Solution (Komnum)/","text":"Numerical Solution of Algebraic and Transcendental Equation \u00b6 Sistem persaman aljabar \u00b6 Persamaan transcendental : sin, cos, tan, Persamaan polynomial : a0 + a1x + a2x2 \u2026\u2026. + anxn + \u2026\u2026 Penyelesaian persamaan non linier \u00b6 Metode Tertutup Mencari akar pada range [a,b] tertentu Dalam range[a,b] dipastikan terdapat satu akar Hasil selalu konvergen \u2192 disebut juga metode konvergen Contohnya Metode Tabel ,Metode Biseksi,Metode Regula Falsi Metode Terbuka Diperlukan tebakan awal xn dipakai untuk menghitung xn+1 Hasil dapat konvergen atau divergen Contohnya Metode Iterasi Sederhana, Metode Newton-Raphson, Metode Secant. method Bisection \u00b6 Metode biseksi ini membagi range menjadi 2 bagian, dari dua bagian ini dipilih bagian mana yang mengandung akar sedangkan bagian yang tidak mengandung akar akan dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh suatu akar persamaan langkah langkah* Tentukan batas bawah (a) dan batas atas (b). Kemudian dihitung nilai tengah : $$ c = {(a+b)\\over 2} $$ Dari nilai c ini perlu dilakukan pengecekan keberadaan akar. Secara matematik, suatu range terdapat akar persamaan bila f(a) dan f(b) berlawanan tanda atau dituliskan : $$ f(a).f(b) <0 $$ Setelah diketahui di bagian mana terdapat akar, maka batas bawah dan batas atas diperbarui sesuai dengan range dari bagian yang mempunyai akar Algoritma metode bisection \u00b6 1.Definisikan fungsi f(x) yang akan dicari akarnya 2.Tentukan nilai a dan b 3.Tentukan toleransi e dan iterasi maksimum N 4.Hitung f(a) dan f(b) 5.Jika f(a).f(b)>0 maka proses dihentikan karena tidak ada akar, bila tidak maka dilanjutkan 6.Hitung x = (a+b)/2 7.Hitung f(x) 8.Bila f(x).f(a)<0 maka b = x dan f(b)=f(x), bila tidak maka a=x dan f(a)=f(x) 9.Jika |b-a|< e atau iterasi > iterasi maks maka proses dihentikan dan didapatkan akar x, bila tidak, ulangi langkah 6 Implementasi metode bisection dalam python \u00b6 def bisection ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Bisection method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = ( a_n + b_n ) / 2 f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Bisection method fails.\" ) return None return ( a_n + b_n ) / 2 f = lambda x : x ** 2 - 5 * x + 6 approx_phi = bisection ( f , 1 , 2.3 , 25 ) print ( approx_phi ) 1.9999999985098835 method Regula Falsi \u00b6 1.Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. 2.Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. 3.Dikenal dengan metode False Position 4.Metode ini juga merupakan penyempurna dari metode bisection Algoritma Method Regula Falsi \u00b6 Definisikan fungsi f(x) Tentukan batas bawah (a) dan batas atas (b) Tentukan toleransi error e Hitung f(a) dan f(b) Untuk iterasi 1 s/d n > e : $$ c= {(f(b).a -f(a).b)\\over (f(b)-f(a))} $$ Hitung f(c)=f(x) \u200b Hitung error = |f(c)| \u200b Jika f(c).f(a)<0 maka nilai a tetap ,jika tidak maka a=c dan f(a)=f(c) Akar persamaanya = c implementasi method regula falsi dalam python \u00b6 error = 0.01 a = 0 b = 2.1 def f ( x ): return x ** 2 - 5 * x + 6 def regulasi_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x if f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regulasi_falsi ( a , b ) x = 2.000000000174259 Metode Newton Raphson \u00b6 Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position Metode ini juga merupakan penyempurna dari metode bisection Prinsip Metode Newton Raphson Metode Newton-Raphson adalah metode pencarian akar suatu fungsi f(x) dengan pendekatan satu titik, dimana fungsi f(x) mempunyai turunan. Metode ini dianggap lebih mudah dari Metode Bagi-Dua (Bisection Method) karena metode ini menggunakan pendekatan satu titik sebagai titik awal. prosedur Menentukan x0 sebagai titik awal. Menarik garis lurus (misal garis P) yang menyinggung titik f(x0). Hal ini berakibat garis P memotong sumbu-x di titik x1. Ulangi langkah sebelumnya tapi sekarang x1 dianggap sebagai titik awalnya. Dari mengulang langkah-langkah sebelumnya akan mendapatkan x1,x2,x3,...,,xn dengan xn yang diperoleh adalah bilangan riil yang merupakan akar atau mendekati akar yang sebenarnya Rumus \u2022Persamaan garis P :y-y0=m(x-x0) \u2022y -f(x0)=f^\u2032 (x0)(x-x0) \u2022x1 adalah perpotongan garis P dengan sumbu-x \u20220-f(x0)=f^\u2032 (x0)(x-x0) \u2022y = 0 dan x = x1 maka koordinat titik (x1,0) \u2022(-f(x0))/(f\u2032(x0))=(x1-x0) \u2022x1=x0 - (f(x0))/(f\u2032(x0)) \u2022x2=x1 - (f(x1))/(f\u2032(x1)) implementasi Metode Newton Raphson python \u00b6 def newton ( f , Df , x0 , epsilon , max_iter ): xn = x0 for n in range ( 0 , max_iter ): fxn = f ( xn ) if abs ( fxn ) < epsilon : print ( 'Found solution after' , n , 'iterations.' ) return xn Dfxn = Df ( xn ) if Dfxn == 0 : print ( 'Zero derivative. No solution found.' ) return None xn = xn - fxn / Dfxn print ( 'Exceeded maximum iterations. No solution found.' ) return None p = lambda x : x ** 2 - 5 * x + 6 Dp = lambda x : 2 * x - 5 approx = newton ( p , Dp , 1 , 1e-3 , 10 ) print ( approx ) Found solution after 4 iterations . 1.9999847409781035 Metode Secant \u00b6 \u25a0Metode Newton Raphson memerlukan perhitungan turunan fungsi f\u2019(x). \u25a0Tidak semua fungsi mudah dicari turunannya terutama fungsi yang bentuknya rumit. \u25a0Turunan fungsi dapat dihilangkan dengan cara menggantinya dengan bentuk lain yang ekivalen \u25a0Modifikasi metode Newton Raphson dinamakan metode Secant. formula secant \u00b6 $$ y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ x = a - f(a)\\frac{b - a}{f(b) - f(a)} $$ Algoritma method secant \u00b6 \u25a0 Definisikan f(x) \u25a0 Definisikan toleransi error e dan iterasi maksimum (n) \u25a0 Masukan dua nilai pendekatan awal yang diantaranya terdapat akar yaitu x_0 dan x_1 ,sebaiknya gunakan metode tabel untuk menjamin titik pendekatanya adalah titik pendekatan yang konvergensinya pada akar persamaan yang diharapkan. \u25a0 Hitung f(x_0 ) dan fx_1 sebagai y_0 dan y_1 \u25a0 Untuk iterasi 1 s/d n x_(i+1)= x_i-(f(xi)(x_i \u3016-x\u3017 (i-1)))/(y_i - y (i-1) ) hitung y_(i+1)=\u3016f(x\u3017_(i+1)) Akar persamaan adalah nilai x yang terakhir implementasi method secant pada python \u00b6 def secant ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Secant method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Secant method fails.\" ) return None return a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) p = lambda x : x ** 2 - 5 * x + 6 approx = secant ( p , 1 , 2.4 , 20 ) print ( approx ) 2.0000003178913373 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Numerical Solution"},{"location":"Numerical Solution (Komnum)/#numerical-solution-of-algebraic-and-transcendental-equation","text":"","title":"Numerical Solution of Algebraic and Transcendental Equation"},{"location":"Numerical Solution (Komnum)/#sistem-persaman-aljabar","text":"Persamaan transcendental : sin, cos, tan, Persamaan polynomial : a0 + a1x + a2x2 \u2026\u2026. + anxn + \u2026\u2026","title":"Sistem persaman aljabar"},{"location":"Numerical Solution (Komnum)/#penyelesaian-persamaan-non-linier","text":"Metode Tertutup Mencari akar pada range [a,b] tertentu Dalam range[a,b] dipastikan terdapat satu akar Hasil selalu konvergen \u2192 disebut juga metode konvergen Contohnya Metode Tabel ,Metode Biseksi,Metode Regula Falsi Metode Terbuka Diperlukan tebakan awal xn dipakai untuk menghitung xn+1 Hasil dapat konvergen atau divergen Contohnya Metode Iterasi Sederhana, Metode Newton-Raphson, Metode Secant.","title":"Penyelesaian persamaan non linier"},{"location":"Numerical Solution (Komnum)/#method-bisection","text":"Metode biseksi ini membagi range menjadi 2 bagian, dari dua bagian ini dipilih bagian mana yang mengandung akar sedangkan bagian yang tidak mengandung akar akan dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh suatu akar persamaan langkah langkah* Tentukan batas bawah (a) dan batas atas (b). Kemudian dihitung nilai tengah : $$ c = {(a+b)\\over 2} $$ Dari nilai c ini perlu dilakukan pengecekan keberadaan akar. Secara matematik, suatu range terdapat akar persamaan bila f(a) dan f(b) berlawanan tanda atau dituliskan : $$ f(a).f(b) <0 $$ Setelah diketahui di bagian mana terdapat akar, maka batas bawah dan batas atas diperbarui sesuai dengan range dari bagian yang mempunyai akar","title":"method Bisection"},{"location":"Numerical Solution (Komnum)/#algoritma-metode-bisection","text":"1.Definisikan fungsi f(x) yang akan dicari akarnya 2.Tentukan nilai a dan b 3.Tentukan toleransi e dan iterasi maksimum N 4.Hitung f(a) dan f(b) 5.Jika f(a).f(b)>0 maka proses dihentikan karena tidak ada akar, bila tidak maka dilanjutkan 6.Hitung x = (a+b)/2 7.Hitung f(x) 8.Bila f(x).f(a)<0 maka b = x dan f(b)=f(x), bila tidak maka a=x dan f(a)=f(x) 9.Jika |b-a|< e atau iterasi > iterasi maks maka proses dihentikan dan didapatkan akar x, bila tidak, ulangi langkah 6","title":"Algoritma metode bisection"},{"location":"Numerical Solution (Komnum)/#implementasi-metode-bisection-dalam-python","text":"def bisection ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Bisection method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = ( a_n + b_n ) / 2 f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Bisection method fails.\" ) return None return ( a_n + b_n ) / 2 f = lambda x : x ** 2 - 5 * x + 6 approx_phi = bisection ( f , 1 , 2.3 , 25 ) print ( approx_phi ) 1.9999999985098835","title":"Implementasi metode bisection dalam python"},{"location":"Numerical Solution (Komnum)/#method-regula-falsi","text":"1.Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. 2.Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. 3.Dikenal dengan metode False Position 4.Metode ini juga merupakan penyempurna dari metode bisection","title":"method Regula Falsi"},{"location":"Numerical Solution (Komnum)/#algoritma-method-regula-falsi","text":"Definisikan fungsi f(x) Tentukan batas bawah (a) dan batas atas (b) Tentukan toleransi error e Hitung f(a) dan f(b) Untuk iterasi 1 s/d n > e : $$ c= {(f(b).a -f(a).b)\\over (f(b)-f(a))} $$ Hitung f(c)=f(x) \u200b Hitung error = |f(c)| \u200b Jika f(c).f(a)<0 maka nilai a tetap ,jika tidak maka a=c dan f(a)=f(c) Akar persamaanya = c","title":"Algoritma Method Regula Falsi"},{"location":"Numerical Solution (Komnum)/#implementasi-method-regula-falsi-dalam-python","text":"error = 0.01 a = 0 b = 2.1 def f ( x ): return x ** 2 - 5 * x + 6 def regulasi_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x if f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regulasi_falsi ( a , b ) x = 2.000000000174259","title":"implementasi method regula falsi dalam python"},{"location":"Numerical Solution (Komnum)/#metode-newton-raphson","text":"Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position Metode ini juga merupakan penyempurna dari metode bisection Prinsip Metode Newton Raphson Metode Newton-Raphson adalah metode pencarian akar suatu fungsi f(x) dengan pendekatan satu titik, dimana fungsi f(x) mempunyai turunan. Metode ini dianggap lebih mudah dari Metode Bagi-Dua (Bisection Method) karena metode ini menggunakan pendekatan satu titik sebagai titik awal. prosedur Menentukan x0 sebagai titik awal. Menarik garis lurus (misal garis P) yang menyinggung titik f(x0). Hal ini berakibat garis P memotong sumbu-x di titik x1. Ulangi langkah sebelumnya tapi sekarang x1 dianggap sebagai titik awalnya. Dari mengulang langkah-langkah sebelumnya akan mendapatkan x1,x2,x3,...,,xn dengan xn yang diperoleh adalah bilangan riil yang merupakan akar atau mendekati akar yang sebenarnya Rumus \u2022Persamaan garis P :y-y0=m(x-x0) \u2022y -f(x0)=f^\u2032 (x0)(x-x0) \u2022x1 adalah perpotongan garis P dengan sumbu-x \u20220-f(x0)=f^\u2032 (x0)(x-x0) \u2022y = 0 dan x = x1 maka koordinat titik (x1,0) \u2022(-f(x0))/(f\u2032(x0))=(x1-x0) \u2022x1=x0 - (f(x0))/(f\u2032(x0)) \u2022x2=x1 - (f(x1))/(f\u2032(x1))","title":"Metode Newton Raphson"},{"location":"Numerical Solution (Komnum)/#implementasi-metode-newton-raphson-python","text":"def newton ( f , Df , x0 , epsilon , max_iter ): xn = x0 for n in range ( 0 , max_iter ): fxn = f ( xn ) if abs ( fxn ) < epsilon : print ( 'Found solution after' , n , 'iterations.' ) return xn Dfxn = Df ( xn ) if Dfxn == 0 : print ( 'Zero derivative. No solution found.' ) return None xn = xn - fxn / Dfxn print ( 'Exceeded maximum iterations. No solution found.' ) return None p = lambda x : x ** 2 - 5 * x + 6 Dp = lambda x : 2 * x - 5 approx = newton ( p , Dp , 1 , 1e-3 , 10 ) print ( approx ) Found solution after 4 iterations . 1.9999847409781035","title":"implementasi Metode Newton Raphson python"},{"location":"Numerical Solution (Komnum)/#metode-secant","text":"\u25a0Metode Newton Raphson memerlukan perhitungan turunan fungsi f\u2019(x). \u25a0Tidak semua fungsi mudah dicari turunannya terutama fungsi yang bentuknya rumit. \u25a0Turunan fungsi dapat dihilangkan dengan cara menggantinya dengan bentuk lain yang ekivalen \u25a0Modifikasi metode Newton Raphson dinamakan metode Secant.","title":"Metode Secant"},{"location":"Numerical Solution (Komnum)/#formula-secant","text":"$$ y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ x = a - f(a)\\frac{b - a}{f(b) - f(a)} $$","title":"formula secant"},{"location":"Numerical Solution (Komnum)/#algoritma-method-secant","text":"\u25a0 Definisikan f(x) \u25a0 Definisikan toleransi error e dan iterasi maksimum (n) \u25a0 Masukan dua nilai pendekatan awal yang diantaranya terdapat akar yaitu x_0 dan x_1 ,sebaiknya gunakan metode tabel untuk menjamin titik pendekatanya adalah titik pendekatan yang konvergensinya pada akar persamaan yang diharapkan. \u25a0 Hitung f(x_0 ) dan fx_1 sebagai y_0 dan y_1 \u25a0 Untuk iterasi 1 s/d n x_(i+1)= x_i-(f(xi)(x_i \u3016-x\u3017 (i-1)))/(y_i - y (i-1) ) hitung y_(i+1)=\u3016f(x\u3017_(i+1)) Akar persamaan adalah nilai x yang terakhir","title":"Algoritma method secant"},{"location":"Numerical Solution (Komnum)/#implementasi-method-secant-pada-python","text":"def secant ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Secant method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Secant method fails.\" ) return None return a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) p = lambda x : x ** 2 - 5 * x + 6 approx = secant ( p , 1 , 2.4 , 20 ) print ( approx ) 2.0000003178913373 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"implementasi method secant pada python"},{"location":"Romberg (komnum)/","text":"METODE INTEGRASI ROMBERG \u00b6 A. Pengertian \u00b6 Integrasi Romberg merupakan teknik yang digunakan dalam integrasi numerik untuk menganalisis kasus dimana fungsi yang akan diintegrasikan tersedia. Teknik ini memiliki keunggulan untuk menghasilkan nilai-nilai dari fungsi yang digunakan untuk mengembangkan skema yang efisien bagi pengintegrasian secara numerik. Integrasi Romberg didasarkan pada ekstrapolasi Richardson ( Richardson's extrapolation ), yaitu metode untuk mengkombinasikan dua perkiraan integral secara numerik untuk memperoleh nilai ketiga, yang lebih akurat. Teknik ini bersifat rekursif dan dapat digunakan untuk menghasilkan sebuah perkiraan integral dalam batas toleransi kesalahan ( error tolerance ) yang sudah ditentukan terlebih dahulu. Metode ini digunakan untuk memperbaiki hasil pendekatan integrasi metode trapesium, karena kesalahan metode trapesium \u201ccukup\u201d besar untuk polinom untuk polinom pangkat tinggi dan fungsi transeden. Pada proses integrasi Romberg, mula-mula kita hitung kuadratur dengan lebar langkah h dan 2h. Defisini kuadratur adalah Untuk menurunkan galat hampiran integral dari O(h2) menjadi O(h2n + 2) dapat digunakan ekstrapolasi Richardson seperti dinyatakan dalam teorema : jika didefinisikan barisan kuadratur {I(i,j) : i >= j dimana j =1, 2, 3, ....} untuk hampiran integral f(x) pada [a, b] sebagai: \u200b I (i, 1) = Ti \u2013 1. i \u2265 1 ( barisan aturan trapezium majemuk) \u200b I (i, 2) = Si \u2013 1. i \u2265 2 (barisan aturan Simpson majemuk) \u200b I (i, 3) = Bi \u2013 1. i \u2265 3 (barisan aturan Boole majemuk) Maka integrasi romberg untuk meningkatkan keakuratan hampiran integral dapat di tulis sebagai B. Code Program \u00b6 import numpy as np def trapezcomp ( f , a , b , n ): \"\"\" Composite trapezoidal function integration INPUTS: f: the function to integrate a: lower bound of integration b: upper bound n: number of panels to create between ``a`` and ``b`` \"\"\" # Initialization h = ( b - a ) / n x = a # Composite rule In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 def romberg ( f , a , b , p ): \"\"\" Romberg integration INPUTS: f: the function to integrate a: lower bound of integration b: upper bound p: number of rows in the Romberg table \"\"\" I = np . zeros (( p , p )) for k in range ( 0 , p ): # Composite trapezoidal rule for 2^k panels I [ k , 0 ] = trapezcomp ( f , a , b , 2 ** k ) # Romberg recursive formula for j in range ( 0 , k ): I [ k , j + 1 ] = ( 4 ** ( j + 1 ) * I [ k , j ] - I [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( I [ k , 0 : k + 1 ]) # display intermediate results return I if __name__ == '__main__' : def func ( x ): return np . sin ( x ) p_rows = 4 I = romberg ( func , 0 , np . pi / 2 , p_rows ) solution = I [ p_rows - 1 , p_rows - 1 ] print ( solution ) # 1.00000000814 C. Output \u00b6 Microsoft Windows [ Version 10.0 . 18362.657 ] ( c ) 2019 Microsoft Corporation . All rights reserved . C : \\ Kuliah \\ KomputasiNumerik > python romberg . py [ 0.78539816 ] [ 0.94805945 1.00227988 ] [ 0.9871158 1.00013458 0.99999157 ] [ 0.99678517 1.0000083 0.99999988 1.00000001 ] 1.0000000081440203","title":"Integrasi Romberg"},{"location":"Romberg (komnum)/#metode-integrasi-romberg","text":"","title":"METODE INTEGRASI ROMBERG"},{"location":"Romberg (komnum)/#a-pengertian","text":"Integrasi Romberg merupakan teknik yang digunakan dalam integrasi numerik untuk menganalisis kasus dimana fungsi yang akan diintegrasikan tersedia. Teknik ini memiliki keunggulan untuk menghasilkan nilai-nilai dari fungsi yang digunakan untuk mengembangkan skema yang efisien bagi pengintegrasian secara numerik. Integrasi Romberg didasarkan pada ekstrapolasi Richardson ( Richardson's extrapolation ), yaitu metode untuk mengkombinasikan dua perkiraan integral secara numerik untuk memperoleh nilai ketiga, yang lebih akurat. Teknik ini bersifat rekursif dan dapat digunakan untuk menghasilkan sebuah perkiraan integral dalam batas toleransi kesalahan ( error tolerance ) yang sudah ditentukan terlebih dahulu. Metode ini digunakan untuk memperbaiki hasil pendekatan integrasi metode trapesium, karena kesalahan metode trapesium \u201ccukup\u201d besar untuk polinom untuk polinom pangkat tinggi dan fungsi transeden. Pada proses integrasi Romberg, mula-mula kita hitung kuadratur dengan lebar langkah h dan 2h. Defisini kuadratur adalah Untuk menurunkan galat hampiran integral dari O(h2) menjadi O(h2n + 2) dapat digunakan ekstrapolasi Richardson seperti dinyatakan dalam teorema : jika didefinisikan barisan kuadratur {I(i,j) : i >= j dimana j =1, 2, 3, ....} untuk hampiran integral f(x) pada [a, b] sebagai: \u200b I (i, 1) = Ti \u2013 1. i \u2265 1 ( barisan aturan trapezium majemuk) \u200b I (i, 2) = Si \u2013 1. i \u2265 2 (barisan aturan Simpson majemuk) \u200b I (i, 3) = Bi \u2013 1. i \u2265 3 (barisan aturan Boole majemuk) Maka integrasi romberg untuk meningkatkan keakuratan hampiran integral dapat di tulis sebagai","title":"A. Pengertian"},{"location":"Romberg (komnum)/#b-code-program","text":"import numpy as np def trapezcomp ( f , a , b , n ): \"\"\" Composite trapezoidal function integration INPUTS: f: the function to integrate a: lower bound of integration b: upper bound n: number of panels to create between ``a`` and ``b`` \"\"\" # Initialization h = ( b - a ) / n x = a # Composite rule In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 def romberg ( f , a , b , p ): \"\"\" Romberg integration INPUTS: f: the function to integrate a: lower bound of integration b: upper bound p: number of rows in the Romberg table \"\"\" I = np . zeros (( p , p )) for k in range ( 0 , p ): # Composite trapezoidal rule for 2^k panels I [ k , 0 ] = trapezcomp ( f , a , b , 2 ** k ) # Romberg recursive formula for j in range ( 0 , k ): I [ k , j + 1 ] = ( 4 ** ( j + 1 ) * I [ k , j ] - I [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( I [ k , 0 : k + 1 ]) # display intermediate results return I if __name__ == '__main__' : def func ( x ): return np . sin ( x ) p_rows = 4 I = romberg ( func , 0 , np . pi / 2 , p_rows ) solution = I [ p_rows - 1 , p_rows - 1 ] print ( solution ) # 1.00000000814","title":"B. Code Program"},{"location":"Romberg (komnum)/#c-output","text":"Microsoft Windows [ Version 10.0 . 18362.657 ] ( c ) 2019 Microsoft Corporation . All rights reserved . C : \\ Kuliah \\ KomputasiNumerik > python romberg . py [ 0.78539816 ] [ 0.94805945 1.00227988 ] [ 0.9871158 1.00013458 0.99999157 ] [ 0.99678517 1.0000083 0.99999988 1.00000001 ] 1.0000000081440203","title":"C. Output"},{"location":"Tugas 3/","text":"Missing Values using KNN \u00b6 KNN adalah algoritma yang berguna untuk mencocokkan suatu titik dengan tetangga terdekatnya dalam ruang multi-dimensi. Ini dapat digunakan untuk data yang kontinu, diskrit, ordinal, dan kategoris yang membuatnya sangat berguna untuk menangani semua jenis data yang hilang. Asumsi di balik menggunakan KNN untuk nilai yang hilang adalah bahwa nilai poin dapat didekati dengan nilai dari poin yang paling dekat dengannya, berdasarkan pada variabel lain. Mari kita simpan contoh sebelumnya dan tambahkan variabel lain, penghasilan orang tersebut. Sekarang kami memiliki tiga variabel, jenis kelamin, pendapatan dan tingkat depresi yang memiliki nilai yang hilang. Kami kemudian berasumsi bahwa orang-orang dengan pendapatan yang sama dan jenis kelamin yang sama cenderung memiliki tingkat depresi yang sama. Untuk nilai yang hilang, kita akan melihat jenis kelamin orang tersebut, pendapatannya, mencari k tetangga terdekatnya dan mendapatkan tingkat depresi mereka. Kita kemudian dapat memperkirakan tingkat depresi orang yang kita inginkan. Kalibrasi Parameter KNN \u00b6 Jumlah tetangga yang harus dicari \u00b6 Mengambil k rendah akan meningkatkan pengaruh kebisingan dan hasilnya akan kurang digeneralisasikan. Di sisi lain, mengambil k tinggi akan cenderung mengaburkan efek lokal yang persis apa yang kita cari. Juga disarankan untuk mengambil k yang aneh untuk kelas biner untuk menghindari ikatan. Metode agregasi untuk digunakan \u00b6 Di sini kita memungkinkan untuk mean aritmatika, median dan mode untuk variabel numerik dan mode untuk yang kategorikal Normalisasi data \u00b6 Ini adalah metode yang memungkinkan setiap atribut memberikan pengaruh yang sama dalam mengidentifikasi tetangga saat menghitung jenis jarak tertentu seperti yang Euclidean. Anda harus menormalkan data Anda ketika skala tidak memiliki arti dan / atau Anda memiliki skala tidak konsisten seperti sentimeter dan meter. Ini menyiratkan pengetahuan sebelumnya tentang data untuk mengetahui mana yang lebih penting. Algoritma secara otomatis menormalkan data ketika variabel numerik dan kategorikal disediakan. Atribut numerik jarak \u00b6 Di antara berbagai metrik jarak yang tersedia, kami akan fokus pada yang utama, Euclidean dan Manhattan. Euclidean adalah ukuran jarak yang baik untuk digunakan jika variabel input bertipe sama (mis. Semua lebar dan tinggi yang diukur). Jarak Manhattan adalah ukuran yang baik untuk digunakan jika variabel input tidak dalam jenis yang sama (seperti usia, tinggi, dll ...). Atribut kategorikal jarak \u00b6 tanpa transformasi sebelumnya, jarak yang berlaku terkait dengan frekuensi dan kesamaan. Atribut kategorikal hampir sama dengan nominal karena dengan tipe ini akan dinormalisasikan menjadi numerik atau angka untuk bisa dirukur jaraknya # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling a missing value with # previous ones df . fillna ( method = 'pad' ) First Score Second Score Third Score 0 100.0 30.0 NaN 1 90.0 45.0 40.0 2 90.0 56.0 80.0 3 95.0 56.0 98.0","title":"missing values"},{"location":"Tugas 3/#missing-values-using-knn","text":"KNN adalah algoritma yang berguna untuk mencocokkan suatu titik dengan tetangga terdekatnya dalam ruang multi-dimensi. Ini dapat digunakan untuk data yang kontinu, diskrit, ordinal, dan kategoris yang membuatnya sangat berguna untuk menangani semua jenis data yang hilang. Asumsi di balik menggunakan KNN untuk nilai yang hilang adalah bahwa nilai poin dapat didekati dengan nilai dari poin yang paling dekat dengannya, berdasarkan pada variabel lain. Mari kita simpan contoh sebelumnya dan tambahkan variabel lain, penghasilan orang tersebut. Sekarang kami memiliki tiga variabel, jenis kelamin, pendapatan dan tingkat depresi yang memiliki nilai yang hilang. Kami kemudian berasumsi bahwa orang-orang dengan pendapatan yang sama dan jenis kelamin yang sama cenderung memiliki tingkat depresi yang sama. Untuk nilai yang hilang, kita akan melihat jenis kelamin orang tersebut, pendapatannya, mencari k tetangga terdekatnya dan mendapatkan tingkat depresi mereka. Kita kemudian dapat memperkirakan tingkat depresi orang yang kita inginkan.","title":"Missing Values using KNN"},{"location":"Tugas 3/#kalibrasi-parameter-knn","text":"","title":"Kalibrasi Parameter KNN"},{"location":"Tugas 3/#jumlah-tetangga-yang-harus-dicari","text":"Mengambil k rendah akan meningkatkan pengaruh kebisingan dan hasilnya akan kurang digeneralisasikan. Di sisi lain, mengambil k tinggi akan cenderung mengaburkan efek lokal yang persis apa yang kita cari. Juga disarankan untuk mengambil k yang aneh untuk kelas biner untuk menghindari ikatan.","title":"Jumlah tetangga yang harus dicari"},{"location":"Tugas 3/#metode-agregasi-untuk-digunakan","text":"Di sini kita memungkinkan untuk mean aritmatika, median dan mode untuk variabel numerik dan mode untuk yang kategorikal","title":"Metode agregasi untuk digunakan"},{"location":"Tugas 3/#normalisasi-data","text":"Ini adalah metode yang memungkinkan setiap atribut memberikan pengaruh yang sama dalam mengidentifikasi tetangga saat menghitung jenis jarak tertentu seperti yang Euclidean. Anda harus menormalkan data Anda ketika skala tidak memiliki arti dan / atau Anda memiliki skala tidak konsisten seperti sentimeter dan meter. Ini menyiratkan pengetahuan sebelumnya tentang data untuk mengetahui mana yang lebih penting. Algoritma secara otomatis menormalkan data ketika variabel numerik dan kategorikal disediakan.","title":"Normalisasi data"},{"location":"Tugas 3/#atribut-numerik-jarak","text":"Di antara berbagai metrik jarak yang tersedia, kami akan fokus pada yang utama, Euclidean dan Manhattan. Euclidean adalah ukuran jarak yang baik untuk digunakan jika variabel input bertipe sama (mis. Semua lebar dan tinggi yang diukur). Jarak Manhattan adalah ukuran yang baik untuk digunakan jika variabel input tidak dalam jenis yang sama (seperti usia, tinggi, dll ...).","title":"Atribut numerik jarak"},{"location":"Tugas 3/#atribut-kategorikal-jarak","text":"tanpa transformasi sebelumnya, jarak yang berlaku terkait dengan frekuensi dan kesamaan. Atribut kategorikal hampir sama dengan nominal karena dengan tipe ini akan dinormalisasikan menjadi numerik atau angka untuk bisa dirukur jaraknya # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling a missing value with # previous ones df . fillna ( method = 'pad' ) First Score Second Score Third Score 0 100.0 30.0 NaN 1 90.0 45.0 40.0 2 90.0 56.0 80.0 3 95.0 56.0 98.0","title":"Atribut kategorikal jarak"},{"location":"Tugas 5 - Clustering/","text":"CLUSTERING \u00b6 Clustering adalah metode penganalisaan data yang sering dimasukkan sebagai salah satu metode Data Mining yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu wilayah yang sama dan data dengan karakteristik yang berbeda ke wilayah yang lain. \u200b Ada beberapa pendekatan yang digunakan dalam mengembangkan metode clustering, dua pendekatan utama adalah clustering dengan pendekatan partisi dan clustering dengan pendekatan hirarki. Clustering dengan pendekatan partisi atau sering disebut dengan partition-based clustering mengelompokkan data dengan memilah-milah data yang dianalisa ke dalam cluster-cluster yang ada. Clustering dengan pendekatan hirarki atau sering disebut dengan hierarchical clustering mengelompokkan data dengan membuat suatu hirarki berupa dendogram dimana data yang mirip akan ditempatkan pada hirarki yang berdekatan dan yang tidak pada hirarki yang berjauhan. Di samping kedua pendekatan tersebut, ada juga clustering dengan pendekatan automatic mapping (Self-Organising Map/SOM). Clustering dengan pendekatan partisi \u00b6 1. K-Means \u200b Salah satu metode yang banyak digunakan dalam melakukan clustering dengan partisi ini adalah metode k-means. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: \u00b7 Tentukan jumlah cluster \u00b7 Alokasikan data secara random ke cluster yang ada \u00b7 Hitung rata-rata setiap cluster dari data yang tergabung di dalamnya \u00b7 Alokasikan kembali semua data ke cluster terdekat \u00b7 Ulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold \u200b Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah crisp atau fuzzy . Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa k-means clustering mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Algoritma K-Means \u00b6 \u200b Secara sederhana algoritma K-Means dimulai dari tahap berikut : . Pilih K buah titik centroid. . Menghitung jarak data dengan centroid. . Update nilai titik centroid. . Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah. Rumus K-Means \u00b6 Metode K-Modes \u00b6 \u200b K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster. Metode K-Prototype \u00b6 \u200b Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu. Algoritma K-Prototype \u00b6 \u200b Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek . Tahap 1 : Tentukan K dengan inisial kluster z1, z2, ..., zk secara acak dari n buah titik {x1, x2, ..., xn} . Tahap 2 : Hitung jarak seluruh data point pada data set terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memiliki jarak prototype terdekat dengan object yang diukur. . Tahap 3 : Hitung titik pusat cluster yang baru setelah semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru. . Tahap 4 : jika titik pusat cluster tidak berubah atau sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih berubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek. Rumus K-Prototype \u00b6 2. Mixture Modelling (Mixture Modeling) \u200b Mixture modelling merupakan metode pengelompokan data yang mirip dengan k-means dengan kelebihan penggunaan distribusi statistik dalam mendefinisikan setiap cluster yang ditemukan. Dibandingkan dengan k-means yang hanya menggunakan cluster center, penggunaan distribusi statistik ini mengijinkan kita untuk: \u00b7 Memodel data yang kita miliki dengan setting karakteristik yang berbeda-beda \u00b7 Jumlah cluster yang sesuai dengan keadaan data bisa ditemukan seiring dengan proses pemodelan karakteristik dari masing-masing cluster \u00b7 Hasil pemodelan clustering yang dilaksanakan bisa diuji tingkat keakuratannya \u200b Distribusi statistik yang digunakan bisa bermacam-macam mulai dari yang digunakan untuk data categorical sampai yang continuous, termasuk di antaranya distribusi binomial, multinomial, normal dan lain-lain. Beberapa distribusi yang bersifat tidak normal seperti distribusi Poisson, von-Mises, Gamma dan Student t, juga diterapkan untuk bisa mengakomodasi berbagai keadaan data yang ada di lapangan. Beberapa pendekatan multivariate juga banyak diterapkan untuk memperhitungkan tingkat keterkaitan antara variabel data yang satu dengan yang lainnya. Clustering dengan Pendekatan Hirarki \u00b6 \u200b Clustering dengan pendekatan hirarki mengelompokkan data yang mirip dalam hirarki yang sama dan yang tidak mirip di hirarki yang agak jauh. Ada dua metode yang sering diterapkan yaitu agglomerative hieararchical clustering dan divisive hierarchical clustering . Agglomerative melakukan proses clustering dari N cluster menjadi satu kesatuan cluster, dimana N adalah jumlah data, sedangkan divisive melakukan proses clustering yang sebaliknya yaitu dari satu cluster menjadi N cluster. \u200b Beberapa metode hierarchical clustering yang sering digunakan dibedakan menurut cara mereka untuk menghitung tingkat kemiripan. Ada yang menggunakan Single Linkage , Complete Linkage , Average Linkage , Average Group Linkage dan lain-lainnya. Seperti juga halnya dengan partition-based clustering , kita juga bisa memilih jenis jarak yang digunakan untuk menghitung tingkat kemiripan antar data. \u200b Salah satu cara untuk mempermudah pengembangan dendogram untuk hierarchical clustering ini adalah dengan membuat similarity matrix yang memuat tingkat kemiripan antar data yang dikelompokkan. Tingkat kemiripan bisa dihitung dengan berbagai macam cara seperti dengan Euclidean Distance Space. Berangkat dari similarity matrix ini, kita bisa memilih lingkage jenis mana yang akan digunakan untuk mengelompokkan data yang dianalisa. Clustering Dengan Pendekatan Automatic Mapping (Self-Organising Map/SOM) \u00b6 \u200b Self-Organising Map merupakan suatu tipe Artificial Neural Networks yang di-training secara unsupervised. SOM menghasilkan map yang terdiri dari output dalam dimensi yang rendah (2 atau 3 dimensi). Map ini berusaha mencari property dari input data. Komposisi input dan output dalam SOM mirip dengan komposisi dari proses feature scaling (multidimensional scaling). \u200b Walaupun proses learning yang dilakukan mirip dengan Artificial Neural Networks, tetapi proses untuk meng-assign input data ke map, lebih mirip dengan K-Means dan kNN Algorithm. Adapun prosedur yang ditempuh dalam melakukan clustering dengan SOM adalah sebagai berikut: \u00b7 Tentukan weight dari input data secara random \u00b7 Pilih salah satu input data \u00b7 Hitung tingkat kesamaan (dengan Eucledian) antara input data dan weight dari input data tersebut dan pilih input data yang memiliki kesamaan dengan weight yang ada (data ini disebut dengan Best Matching Unit (BMU)) \u00b7 Perbaharui weight dari input data dengan mendekatkan weight tersebut ke BMU dengan rumus: Wv(t+1) = Wv(t) + Theta(v, t) x Alpha(t) x (D(t) \u2013 Wv(t)) Dimana: o Wv(t) : Weight pada saat ke-t o Theta (v, t) : Fungsi neighbourhood yang tergantung pada Lattice distance antara BMU dengan neuron v. Umumnya bernilai 1 untuk neuron yang cukup dekat dengan BMU, dan 0 untuk yang sebaliknya. Penggunaan fungsi Gaussian juga memungkinkan. o Alpha (t) : Learning Coefficient yang berkurang secara monotonic o D(t) : Input data \u00b7 Tambah nilai t, sampai t < Lambda , dimana Lambda adalah jumlah iterasi MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering"},{"location":"Tugas 5 - Clustering/#clustering","text":"Clustering adalah metode penganalisaan data yang sering dimasukkan sebagai salah satu metode Data Mining yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu wilayah yang sama dan data dengan karakteristik yang berbeda ke wilayah yang lain. \u200b Ada beberapa pendekatan yang digunakan dalam mengembangkan metode clustering, dua pendekatan utama adalah clustering dengan pendekatan partisi dan clustering dengan pendekatan hirarki. Clustering dengan pendekatan partisi atau sering disebut dengan partition-based clustering mengelompokkan data dengan memilah-milah data yang dianalisa ke dalam cluster-cluster yang ada. Clustering dengan pendekatan hirarki atau sering disebut dengan hierarchical clustering mengelompokkan data dengan membuat suatu hirarki berupa dendogram dimana data yang mirip akan ditempatkan pada hirarki yang berdekatan dan yang tidak pada hirarki yang berjauhan. Di samping kedua pendekatan tersebut, ada juga clustering dengan pendekatan automatic mapping (Self-Organising Map/SOM).","title":"CLUSTERING"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-partisi","text":"1. K-Means \u200b Salah satu metode yang banyak digunakan dalam melakukan clustering dengan partisi ini adalah metode k-means. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: \u00b7 Tentukan jumlah cluster \u00b7 Alokasikan data secara random ke cluster yang ada \u00b7 Hitung rata-rata setiap cluster dari data yang tergabung di dalamnya \u00b7 Alokasikan kembali semua data ke cluster terdekat \u00b7 Ulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold \u200b Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah crisp atau fuzzy . Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa k-means clustering mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut.","title":"Clustering dengan pendekatan partisi"},{"location":"Tugas 5 - Clustering/#algoritma-k-means","text":"\u200b Secara sederhana algoritma K-Means dimulai dari tahap berikut : . Pilih K buah titik centroid. . Menghitung jarak data dengan centroid. . Update nilai titik centroid. . Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah.","title":"Algoritma K-Means"},{"location":"Tugas 5 - Clustering/#rumus-k-means","text":"","title":"Rumus K-Means"},{"location":"Tugas 5 - Clustering/#metode-k-modes","text":"\u200b K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster.","title":"Metode K-Modes"},{"location":"Tugas 5 - Clustering/#metode-k-prototype","text":"\u200b Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu.","title":"Metode K-Prototype"},{"location":"Tugas 5 - Clustering/#algoritma-k-prototype","text":"\u200b Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek . Tahap 1 : Tentukan K dengan inisial kluster z1, z2, ..., zk secara acak dari n buah titik {x1, x2, ..., xn} . Tahap 2 : Hitung jarak seluruh data point pada data set terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memiliki jarak prototype terdekat dengan object yang diukur. . Tahap 3 : Hitung titik pusat cluster yang baru setelah semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru. . Tahap 4 : jika titik pusat cluster tidak berubah atau sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih berubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek.","title":"Algoritma K-Prototype"},{"location":"Tugas 5 - Clustering/#rumus-k-prototype","text":"2. Mixture Modelling (Mixture Modeling) \u200b Mixture modelling merupakan metode pengelompokan data yang mirip dengan k-means dengan kelebihan penggunaan distribusi statistik dalam mendefinisikan setiap cluster yang ditemukan. Dibandingkan dengan k-means yang hanya menggunakan cluster center, penggunaan distribusi statistik ini mengijinkan kita untuk: \u00b7 Memodel data yang kita miliki dengan setting karakteristik yang berbeda-beda \u00b7 Jumlah cluster yang sesuai dengan keadaan data bisa ditemukan seiring dengan proses pemodelan karakteristik dari masing-masing cluster \u00b7 Hasil pemodelan clustering yang dilaksanakan bisa diuji tingkat keakuratannya \u200b Distribusi statistik yang digunakan bisa bermacam-macam mulai dari yang digunakan untuk data categorical sampai yang continuous, termasuk di antaranya distribusi binomial, multinomial, normal dan lain-lain. Beberapa distribusi yang bersifat tidak normal seperti distribusi Poisson, von-Mises, Gamma dan Student t, juga diterapkan untuk bisa mengakomodasi berbagai keadaan data yang ada di lapangan. Beberapa pendekatan multivariate juga banyak diterapkan untuk memperhitungkan tingkat keterkaitan antara variabel data yang satu dengan yang lainnya.","title":"Rumus K-Prototype"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-hirarki","text":"\u200b Clustering dengan pendekatan hirarki mengelompokkan data yang mirip dalam hirarki yang sama dan yang tidak mirip di hirarki yang agak jauh. Ada dua metode yang sering diterapkan yaitu agglomerative hieararchical clustering dan divisive hierarchical clustering . Agglomerative melakukan proses clustering dari N cluster menjadi satu kesatuan cluster, dimana N adalah jumlah data, sedangkan divisive melakukan proses clustering yang sebaliknya yaitu dari satu cluster menjadi N cluster. \u200b Beberapa metode hierarchical clustering yang sering digunakan dibedakan menurut cara mereka untuk menghitung tingkat kemiripan. Ada yang menggunakan Single Linkage , Complete Linkage , Average Linkage , Average Group Linkage dan lain-lainnya. Seperti juga halnya dengan partition-based clustering , kita juga bisa memilih jenis jarak yang digunakan untuk menghitung tingkat kemiripan antar data. \u200b Salah satu cara untuk mempermudah pengembangan dendogram untuk hierarchical clustering ini adalah dengan membuat similarity matrix yang memuat tingkat kemiripan antar data yang dikelompokkan. Tingkat kemiripan bisa dihitung dengan berbagai macam cara seperti dengan Euclidean Distance Space. Berangkat dari similarity matrix ini, kita bisa memilih lingkage jenis mana yang akan digunakan untuk mengelompokkan data yang dianalisa.","title":"Clustering dengan Pendekatan Hirarki"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-automatic-mapping-self-organising-mapsom","text":"\u200b Self-Organising Map merupakan suatu tipe Artificial Neural Networks yang di-training secara unsupervised. SOM menghasilkan map yang terdiri dari output dalam dimensi yang rendah (2 atau 3 dimensi). Map ini berusaha mencari property dari input data. Komposisi input dan output dalam SOM mirip dengan komposisi dari proses feature scaling (multidimensional scaling). \u200b Walaupun proses learning yang dilakukan mirip dengan Artificial Neural Networks, tetapi proses untuk meng-assign input data ke map, lebih mirip dengan K-Means dan kNN Algorithm. Adapun prosedur yang ditempuh dalam melakukan clustering dengan SOM adalah sebagai berikut: \u00b7 Tentukan weight dari input data secara random \u00b7 Pilih salah satu input data \u00b7 Hitung tingkat kesamaan (dengan Eucledian) antara input data dan weight dari input data tersebut dan pilih input data yang memiliki kesamaan dengan weight yang ada (data ini disebut dengan Best Matching Unit (BMU)) \u00b7 Perbaharui weight dari input data dengan mendekatkan weight tersebut ke BMU dengan rumus: Wv(t+1) = Wv(t) + Theta(v, t) x Alpha(t) x (D(t) \u2013 Wv(t)) Dimana: o Wv(t) : Weight pada saat ke-t o Theta (v, t) : Fungsi neighbourhood yang tergantung pada Lattice distance antara BMU dengan neuron v. Umumnya bernilai 1 untuk neuron yang cukup dekat dengan BMU, dan 0 untuk yang sebaliknya. Penggunaan fungsi Gaussian juga memungkinkan. o Alpha (t) : Learning Coefficient yang berkurang secara monotonic o D(t) : Input data \u00b7 Tambah nilai t, sampai t < Lambda , dimana Lambda adalah jumlah iterasi MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering Dengan Pendekatan Automatic Mapping (Self-Organising Map/SOM)"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/","text":"Regresi Linier Sederhana dan Berganda \u00b6 Dalam berbagai penulisan laporan penelitian ilmiah, analisis regresi banyak sekali digunakan. Bahkan, bisa jadi, analisis ini paling banyak digunakan. Analisis regresi menunjukkan pengaruh variabel independen atau variabel bebas (X) terhadap variabel dependen atau variabel tergantung (Y). Dengan demikian, setidaknya ada 2 variabel yang terlibat dalam uji atau analisis regresi yaitu 1). variabel independen atau variabel bebas (X), dan 2) variabel dependen atau variabel tergantung (Y). Regresi Linier Sederhana \u00b6 Regresi linier sederhana adalah regresi yang hanya melibatkan dua variabel, yaitu 1 (satu) variabel dependen atau variabel tergantung dan 1 (satu) variabel independen atau bebas. Persamaan di atas adalah rumus dari persamaan regresi linear sederhana. Y adalah variabel tak bebas, a adalah koefisien intersep, b adalah kemiringan dan t adalah variabel bebas. Rumus untuk b adalah : Dan rumus untuk mendapatkan nilai a adalah sebagai berikut : Dalam regresi linear sederhana juga ada yang disebut dengan koefisien korelasi yang menunjukkan bahwa nilai suatu variabel bergantung pada perubahan nilai variabel yang lain. Rumus untuk menghitung koefisien korelasi adalah sebagai berikut : Regresi Linier Berganda \u00b6 Regresi linier berganda adalah hubungan secara linear antara dua atau lebih variabel independen (X1, X2,\u2026.Xn) dengan variabel dependen (Y). Analisis ini untuk mengetahui arah hubungan antara variabel independen dengan variabel dependen apakah masing-masing variabel independen berhubungan positif atau negatif dan untuk memprediksi nilai dari variabel dependen apabila nilai variabel independen mengalami kenaikan atau penurunan. Data yang digunakan biasanya berskala interval atau rasio. Persamaan regresi linear berganda sebagai berikut: Y\u2019 = a + b1X1+ b2X2+\u2026..+ bnXn Keterangan: Y\u2019 = Variabel dependen (nilai yang diprediksikan) X1 dan X2 = Variabel independen a = Konstanta (nilai Y\u2019 apabila X1, X2\u2026..Xn = 0) b = Koefisien regresi (nilai peningkatan ataupun penurunan) Contoh kasus dengan penghitungan manual \u00b6 Seorang Engineer ingin mempelajari Hubungan antara Suhu Ruangan dengan Jumlah Cacat yang diakibatkannya, sehingga dapat memprediksi atau meramalkan jumlah cacat produksi jika suhu ruangan tersebut tidak terkendali. Engineer tersebut kemudian mengambil data selama 30 hari terhadap rata-rata (mean) suhu ruangan dan Jumlah Cacat Produksi. Langkah 1 : Penentuan Tujuan \u00b6 Tujuan : Memprediksi Jumlah cacat produksi jika suhu ruangan tidak terkendali Langkah 2 : Identifikasikan Variabel Penyebab dan Akibat \u00b6 Varibel Faktor Penyebab (X) : Suhu Ruangan, Variabel Akibat (Y) : Jumlah Cacat Produksi Langkah 3 : Pengumpulan Data \u00b6 Berikut ini adalah data yang berhasil dikumpulkan selama 30 hari (berbentuk tabel) : Tanggal Rata-rata Suhu Ruangan Jumlah Cacat 1 24 10 2 22 5 3 21 6 4 20 3 5 22 6 6 19 4 7 20 5 8 23 9 9 24 11 10 25 13 11 21 7 12 20 4 13 20 6 14 19 3 15 25 12 16 27 13 17 28 16 18 25 12 19 26 14 20 24 12 21 27 16 22 23 9 23 24 13 24 23 11 25 22 7 26 21 5 27 26 12 28 25 11 29 26 13 30 27 14 Langkah 4 : Hitung X\u00b2, Y\u00b2, XY dan total dari masing-masingnya \u00b6 Berikut ini adalah tabel yang telah dilakukan perhitungan X\u00b2, Y\u00b2, XY dan totalnya : Langkah 5 : Hitung a dan b berdasarkan rumus Regresi Linear Sederhana \u00b6 Langkah 6 : Buat Model Persamaan Regresi \u00b6 Y = a + bX Y = -24,38 + 1,45X Langkah 7 : Lakukan Prediksi atau Peramalan terhadap Variabel Faktor Penyebab atau Variabel Akibat \u00b6 I. Prediksikan Jumlah Cacat Produksi jika suhu dalam keadaan tinggi (Variabel X), contohnya : 30\u00b0C Y = -24,38 + 1,45 (30) Y = 19,12 Jadi Jika Suhu ruangan mencapai 30\u00b0C, maka akan diprediksikan akan terdapat 19,12 unit cacat yang dihasilkan oleh produksi. II. Jika Cacat Produksi (Variabel Y) yang ditargetkan hanya boleh 4 unit, maka berapakah suhu ruangan yang diperlukan untuk mencapai target tersebut ? 4 = -24,38 + 1,45X 1,45X = 4 + 24,38 X = 28,38 / 1,45X = 19,57 Jadi Prediksi Suhu Ruangan yang paling sesuai untuk mencapai target Cacat Produksi adalah sekitar 19,57\u00b0C Contoh kasus dengan penghitungan sklearn \u00b6 Dalam pembelajaran kali ini, kita ingin mencari solusi dari proses perekrutan sebuah perusahaan. Perusahaan ini sedang merekrut seorang calon pegawai baru. Namun, bagian HRD perusahaan ini kebingungan, berapa gaji yang harus ia berikan, sesuai dengan level di mana calon pegawai baru ini masuk. Tentunya akan ada proses negosiasi antara HRD dengan calon pegawai baru ini tentang jumlah gaji yang pantas diterima pegawai tersebut. Calon pegawai ini mengaku bahwa sebelumnya ia telah berada di posisi Region Manager dengan pengalaman bekerja 20 tahun lebih dengan gaji hampir 160K dollar per tahun. Ia meminta perusahaan baru ini untuk memberikan ia gaji lebih dari 160K dollar per tahun. Untuk menyelidiki apakah calon pegawai ini benar-benar digaji sebanyak 160K dollar/tahun, maka bagian HRD membandingkan data gaji perusahaan tempat calon pegawai ini bekerja sebelumnya (kebetulan perusahaan memiliki daftar gajinya) dengan pengakuannya. Data yang dimiliki adalah daftar antara gaji dan level di perusahaan tersebut. Bagian HRD ingin mencari hubungan antara gaji yang didapat dengan level (tingkatan jabatan) di perusahaan calon pekerja tadi bekerja sebelumnya. Hasil penelitian awal, calon pegawai ini layak masuk di level 6.5 (antara region manager dan partner ). Berikut variabel yang kita miliki: Variabel dependen : Gaji (dalam dollar per tahun) Variabel independen : level (tingkatan jabatan) Setelah melihat tabelnya, bisa dilihat bahwa kita memiliki 1 variabel dependen, dan 1 variabel independen. Dari sini kita bisa tahu bahwa kita bisa menggunakan pendekatan model regresi sederhana. Walau demikian, datanya sudah diatur sedemikian rupa sehingga fungsi yang dimiliki antara variabel dependen dengan independen adalah kuadratik. Kita tetap akan mencoba membuat 2 model (simple dan polinomial) untuk membandingkan performanya (seberapa fit antara 2 model regresi ini dengan data). # Mengimpor library import`` numpy as np import`` matplotlib.pyplot as plt import`` pandas as pd Line 2 sampai line 4 mengimpor library yang diperlukan # Mengimpor dataset dataset ``=`` pd.read_csv(``'Posisi_gaji.csv'``) X ``=`` dataset.iloc[:, ``1``:``2``].values y ``=`` dataset.iloc[:, ``2``].values Line 7 mengimpor datasetnya Line 8 menentukan variabel independen X. Penting, bahwa usahakan variabel independen adalah matrix, dan bukan vector. Kita bisa saja menuliskan X = dataset.iloc[:, 1].values , namun perintah ini akan menghasilkan vector. Biasakan membuatnya sebagai sebuah matrix, dengan cara melakukan slicing X = dataset.iloc[:, 1:2].values . Bagaimana kita tahu X sudah menjadi matrix? Bisa dilihat kolom size di spyder variabel X adalah (10,1). Artinya X adalah matrix 10\u00d71 (10 baris dan 1 kolom). Line 9 menentukan variabel dependen y. Penting, usahakan variabel dependen adalah vector. Vektor ( vector ) adalah matriks yang hanya terdiri dari 1 kolom, atau matriks 1 baris. Cara membuatnya menjadi vektor adalah jangan lakukan slicing pada bagian kolomnya. Pada bagian size variabel y di spyder adalah (10,) yang artinya ia adalah matrix 1 baris. # Fitting Linear Regression ke dataset from`` sklearn.linear_model ``import`` LinearRegression lin_reg ``=`` LinearRegression() lin_reg.fit(X, y) Line 12 mengimpor class LinearRegression (untuk membuat model regresi sederhana) Line 13 mempersiapkan objek lin_reg sebagai model regresi sederhana Line 14 membuat model regresi sederhana (Kali ini tanpa membagi dataset ke dalam test dan train set, karena datasetnya terlalu kecil (biasanya train set minimal butuh 10 baris, dan kali ini tidak cukup data untuk dimasukkan ke test set). Walau demikian, model yang jadi nanti akan merupakan bagian dari train set, dan dataset baru yang diterima (pengujian train set) akan menjadi test set-nya). # Fitting Polynomial Regression ke dataset from`` sklearn.preprocessing ``import`` PolynomialFeatures poly_reg ``=`` PolynomialFeatures(degree ``=`` ``2``) ``## nantinya degree diganti menjadi 4 X_poly ``=`` poly_reg.fit_transform(X) lin_reg_2 ``=`` LinearRegression() lin_reg_2.fit(X_poly, y) Line 17 mengimpor PolynomialFeatures dari library sklearn.preprocessing untuk membuat model polinomial. Untuk mengetahui parameter apa saja yang diperlukan, cukup arahkan kursor pada PolynomialFeatures, lalu klik CTRL+i. Line 18 mempersiapkan objek poly_reg sebagai transformasi matriks X menjadi matriks X pangkat 2, pangkat 3 hingga pangkat n. Jadi nantinya kita memiliki beberapa tambahan variabel independen sebanyak n. Parameter default untuk PolynomialFeatures adalah degrees=2. Line 19 menyiapkan objek X_poly sebagai hasil fit_transform (proses fit dan transform dilakukan sekaligus) dari variabel X. Mari kita bandingkan antara X dengan X_poly. Line 20 menyiapkan objek lin_reg_2 sebagai model regresi polinomial. Line 21 membuat model regresi polinomial dengan parameter variabel independen adalah X_poly, dan variabel dependennya adalah y. # Visualisasi hasil regresi sederhana plt.scatter(X, y, color ``=`` ``'red'``) plt.plot(X, lin_reg.predict(X), color ``=`` ``'blue'``) plt.title(``'Sesuai atau tidak (Linear Regression)'``) plt.xlabel(``'Level posisi'``) plt.ylabel(``'Gaji'``) plt.show() Line 24 sampai line 29 adalah perintah untuk visualisasi hasil model regresi sederhana kita. Ingat untuk visualisasi, perintah dari line 24-29 harus dieksekusi bersamaan. Visualisasinya akan nampak sebagai berikut : # Visualisasi hasil regresi polynomial plt.scatter(X, y, color ``=`` ``'red'``) plt.plot(X, lin_reg_2.predict(X_poly), color ``=`` ``'blue'``) plt.title(``'Sesuai atau tidak (Polynomial Regression)'``) plt.xlabel(``'Level posisi'``) plt.ylabel(``'Gaji'``) plt.show() Line 32 sampai line 37 adalah perintah untuk visualisasi hasil model regresi polinomial. Pelru diingat sumbu y nya adalah lin_reg_2.predict(X_poly) . Hasilnya akan tampak sebagai berikut : Bisa dilihat dengan menggunakan fungsi polinomial hasilnya cukup baik. Namun tetap saja masih kurang cukup fit , di mana masih ada jarak antara model dengan data. Solusinya adalah pada line 18 kita ubah degree nya dari 2 menjadi 4. Eksekusi line 18 sampai line 21. Kemudian eksekusi line 32 sampai line 37. Maka visualisasi yang baru akan tampak sebagai berikut : # Memprediksi hasil dengan regresi sederhana lin_reg.predict(``6.5``) Line 40 adalah perintah untuk melihat dengan model regresi sederhana yang sudah dibuat, berapa gaji yang layak untuk tingkat level 6.5? Maka cukup ganti parameter X di lin_reg.predict(X) dengan angka 6.5. Jika dieksekusi, hasilnya adalah 330378.78 dollar/tahun. Tentunya prediksi dari regresi sederhana terlalu tinggi (terlihat juga di plot visualisasinya). Kita tidak menginginkan gaji yang terlalu tinggi yang merupakan hasil dari model regresi sederhana yang buruk kali ini. # Memprediksi hasil dengan regresi polynomial lin_reg_2.predict(poly_reg.fit_transform(``6.5``)) Line 43 adalah perintah untuk melihat prediksi gaji dengan model regresi polinomial. Perlu diperhatikan bahwa parameter X diganti dengan poly_reg.fit_transform(6.5) dan bukan X_poly. Karena kita ingin mengisi angka 6.5 sebagai parameter X. Sementara X_poky adalah hasil dari definisi fungsi poly_reg.fit_transform(X). Ketika dieksekusi maka hasilnya adalah 158862.45 dollar/tahun. Prediksi yang cukup baik, dengan model yang fit. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Regresi Linier Sederhana dan Berganda"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#regresi-linier-sederhana-dan-berganda","text":"Dalam berbagai penulisan laporan penelitian ilmiah, analisis regresi banyak sekali digunakan. Bahkan, bisa jadi, analisis ini paling banyak digunakan. Analisis regresi menunjukkan pengaruh variabel independen atau variabel bebas (X) terhadap variabel dependen atau variabel tergantung (Y). Dengan demikian, setidaknya ada 2 variabel yang terlibat dalam uji atau analisis regresi yaitu 1). variabel independen atau variabel bebas (X), dan 2) variabel dependen atau variabel tergantung (Y).","title":"Regresi Linier Sederhana dan Berganda"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#regresi-linier-sederhana","text":"Regresi linier sederhana adalah regresi yang hanya melibatkan dua variabel, yaitu 1 (satu) variabel dependen atau variabel tergantung dan 1 (satu) variabel independen atau bebas. Persamaan di atas adalah rumus dari persamaan regresi linear sederhana. Y adalah variabel tak bebas, a adalah koefisien intersep, b adalah kemiringan dan t adalah variabel bebas. Rumus untuk b adalah : Dan rumus untuk mendapatkan nilai a adalah sebagai berikut : Dalam regresi linear sederhana juga ada yang disebut dengan koefisien korelasi yang menunjukkan bahwa nilai suatu variabel bergantung pada perubahan nilai variabel yang lain. Rumus untuk menghitung koefisien korelasi adalah sebagai berikut :","title":"Regresi Linier Sederhana"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#regresi-linier-berganda","text":"Regresi linier berganda adalah hubungan secara linear antara dua atau lebih variabel independen (X1, X2,\u2026.Xn) dengan variabel dependen (Y). Analisis ini untuk mengetahui arah hubungan antara variabel independen dengan variabel dependen apakah masing-masing variabel independen berhubungan positif atau negatif dan untuk memprediksi nilai dari variabel dependen apabila nilai variabel independen mengalami kenaikan atau penurunan. Data yang digunakan biasanya berskala interval atau rasio. Persamaan regresi linear berganda sebagai berikut: Y\u2019 = a + b1X1+ b2X2+\u2026..+ bnXn Keterangan: Y\u2019 = Variabel dependen (nilai yang diprediksikan) X1 dan X2 = Variabel independen a = Konstanta (nilai Y\u2019 apabila X1, X2\u2026..Xn = 0) b = Koefisien regresi (nilai peningkatan ataupun penurunan)","title":"Regresi Linier Berganda"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#contoh-kasus-dengan-penghitungan-manual","text":"Seorang Engineer ingin mempelajari Hubungan antara Suhu Ruangan dengan Jumlah Cacat yang diakibatkannya, sehingga dapat memprediksi atau meramalkan jumlah cacat produksi jika suhu ruangan tersebut tidak terkendali. Engineer tersebut kemudian mengambil data selama 30 hari terhadap rata-rata (mean) suhu ruangan dan Jumlah Cacat Produksi.","title":"Contoh kasus dengan penghitungan manual"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-1-penentuan-tujuan","text":"Tujuan : Memprediksi Jumlah cacat produksi jika suhu ruangan tidak terkendali","title":"Langkah 1 : Penentuan Tujuan"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-2-identifikasikan-variabel-penyebab-dan-akibat","text":"Varibel Faktor Penyebab (X) : Suhu Ruangan, Variabel Akibat (Y) : Jumlah Cacat Produksi","title":"Langkah 2 : Identifikasikan Variabel Penyebab dan Akibat"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-3-pengumpulan-data","text":"Berikut ini adalah data yang berhasil dikumpulkan selama 30 hari (berbentuk tabel) : Tanggal Rata-rata Suhu Ruangan Jumlah Cacat 1 24 10 2 22 5 3 21 6 4 20 3 5 22 6 6 19 4 7 20 5 8 23 9 9 24 11 10 25 13 11 21 7 12 20 4 13 20 6 14 19 3 15 25 12 16 27 13 17 28 16 18 25 12 19 26 14 20 24 12 21 27 16 22 23 9 23 24 13 24 23 11 25 22 7 26 21 5 27 26 12 28 25 11 29 26 13 30 27 14","title":"Langkah 3 : Pengumpulan Data"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-4-hitung-x2-y2-xy-dan-total-dari-masing-masingnya","text":"Berikut ini adalah tabel yang telah dilakukan perhitungan X\u00b2, Y\u00b2, XY dan totalnya :","title":"Langkah 4 : Hitung X\u00b2, Y\u00b2, XY dan total dari masing-masingnya"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-5-hitung-a-dan-b-berdasarkan-rumus-regresi-linear-sederhana","text":"","title":"Langkah 5 : Hitung a dan b berdasarkan rumus Regresi Linear Sederhana"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-6-buat-model-persamaan-regresi","text":"Y = a + bX Y = -24,38 + 1,45X","title":"Langkah 6 : Buat Model Persamaan Regresi"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#langkah-7-lakukan-prediksi-atau-peramalan-terhadap-variabel-faktor-penyebab-atau-variabel-akibat","text":"I. Prediksikan Jumlah Cacat Produksi jika suhu dalam keadaan tinggi (Variabel X), contohnya : 30\u00b0C Y = -24,38 + 1,45 (30) Y = 19,12 Jadi Jika Suhu ruangan mencapai 30\u00b0C, maka akan diprediksikan akan terdapat 19,12 unit cacat yang dihasilkan oleh produksi. II. Jika Cacat Produksi (Variabel Y) yang ditargetkan hanya boleh 4 unit, maka berapakah suhu ruangan yang diperlukan untuk mencapai target tersebut ? 4 = -24,38 + 1,45X 1,45X = 4 + 24,38 X = 28,38 / 1,45X = 19,57 Jadi Prediksi Suhu Ruangan yang paling sesuai untuk mencapai target Cacat Produksi adalah sekitar 19,57\u00b0C","title":"Langkah 7 : Lakukan Prediksi atau Peramalan terhadap Variabel Faktor Penyebab atau Variabel Akibat"},{"location":"Tugas 7 - Regresi Linier Sederhana dan Berganda/#contoh-kasus-dengan-penghitungan-sklearn","text":"Dalam pembelajaran kali ini, kita ingin mencari solusi dari proses perekrutan sebuah perusahaan. Perusahaan ini sedang merekrut seorang calon pegawai baru. Namun, bagian HRD perusahaan ini kebingungan, berapa gaji yang harus ia berikan, sesuai dengan level di mana calon pegawai baru ini masuk. Tentunya akan ada proses negosiasi antara HRD dengan calon pegawai baru ini tentang jumlah gaji yang pantas diterima pegawai tersebut. Calon pegawai ini mengaku bahwa sebelumnya ia telah berada di posisi Region Manager dengan pengalaman bekerja 20 tahun lebih dengan gaji hampir 160K dollar per tahun. Ia meminta perusahaan baru ini untuk memberikan ia gaji lebih dari 160K dollar per tahun. Untuk menyelidiki apakah calon pegawai ini benar-benar digaji sebanyak 160K dollar/tahun, maka bagian HRD membandingkan data gaji perusahaan tempat calon pegawai ini bekerja sebelumnya (kebetulan perusahaan memiliki daftar gajinya) dengan pengakuannya. Data yang dimiliki adalah daftar antara gaji dan level di perusahaan tersebut. Bagian HRD ingin mencari hubungan antara gaji yang didapat dengan level (tingkatan jabatan) di perusahaan calon pekerja tadi bekerja sebelumnya. Hasil penelitian awal, calon pegawai ini layak masuk di level 6.5 (antara region manager dan partner ). Berikut variabel yang kita miliki: Variabel dependen : Gaji (dalam dollar per tahun) Variabel independen : level (tingkatan jabatan) Setelah melihat tabelnya, bisa dilihat bahwa kita memiliki 1 variabel dependen, dan 1 variabel independen. Dari sini kita bisa tahu bahwa kita bisa menggunakan pendekatan model regresi sederhana. Walau demikian, datanya sudah diatur sedemikian rupa sehingga fungsi yang dimiliki antara variabel dependen dengan independen adalah kuadratik. Kita tetap akan mencoba membuat 2 model (simple dan polinomial) untuk membandingkan performanya (seberapa fit antara 2 model regresi ini dengan data). # Mengimpor library import`` numpy as np import`` matplotlib.pyplot as plt import`` pandas as pd Line 2 sampai line 4 mengimpor library yang diperlukan # Mengimpor dataset dataset ``=`` pd.read_csv(``'Posisi_gaji.csv'``) X ``=`` dataset.iloc[:, ``1``:``2``].values y ``=`` dataset.iloc[:, ``2``].values Line 7 mengimpor datasetnya Line 8 menentukan variabel independen X. Penting, bahwa usahakan variabel independen adalah matrix, dan bukan vector. Kita bisa saja menuliskan X = dataset.iloc[:, 1].values , namun perintah ini akan menghasilkan vector. Biasakan membuatnya sebagai sebuah matrix, dengan cara melakukan slicing X = dataset.iloc[:, 1:2].values . Bagaimana kita tahu X sudah menjadi matrix? Bisa dilihat kolom size di spyder variabel X adalah (10,1). Artinya X adalah matrix 10\u00d71 (10 baris dan 1 kolom). Line 9 menentukan variabel dependen y. Penting, usahakan variabel dependen adalah vector. Vektor ( vector ) adalah matriks yang hanya terdiri dari 1 kolom, atau matriks 1 baris. Cara membuatnya menjadi vektor adalah jangan lakukan slicing pada bagian kolomnya. Pada bagian size variabel y di spyder adalah (10,) yang artinya ia adalah matrix 1 baris. # Fitting Linear Regression ke dataset from`` sklearn.linear_model ``import`` LinearRegression lin_reg ``=`` LinearRegression() lin_reg.fit(X, y) Line 12 mengimpor class LinearRegression (untuk membuat model regresi sederhana) Line 13 mempersiapkan objek lin_reg sebagai model regresi sederhana Line 14 membuat model regresi sederhana (Kali ini tanpa membagi dataset ke dalam test dan train set, karena datasetnya terlalu kecil (biasanya train set minimal butuh 10 baris, dan kali ini tidak cukup data untuk dimasukkan ke test set). Walau demikian, model yang jadi nanti akan merupakan bagian dari train set, dan dataset baru yang diterima (pengujian train set) akan menjadi test set-nya). # Fitting Polynomial Regression ke dataset from`` sklearn.preprocessing ``import`` PolynomialFeatures poly_reg ``=`` PolynomialFeatures(degree ``=`` ``2``) ``## nantinya degree diganti menjadi 4 X_poly ``=`` poly_reg.fit_transform(X) lin_reg_2 ``=`` LinearRegression() lin_reg_2.fit(X_poly, y) Line 17 mengimpor PolynomialFeatures dari library sklearn.preprocessing untuk membuat model polinomial. Untuk mengetahui parameter apa saja yang diperlukan, cukup arahkan kursor pada PolynomialFeatures, lalu klik CTRL+i. Line 18 mempersiapkan objek poly_reg sebagai transformasi matriks X menjadi matriks X pangkat 2, pangkat 3 hingga pangkat n. Jadi nantinya kita memiliki beberapa tambahan variabel independen sebanyak n. Parameter default untuk PolynomialFeatures adalah degrees=2. Line 19 menyiapkan objek X_poly sebagai hasil fit_transform (proses fit dan transform dilakukan sekaligus) dari variabel X. Mari kita bandingkan antara X dengan X_poly. Line 20 menyiapkan objek lin_reg_2 sebagai model regresi polinomial. Line 21 membuat model regresi polinomial dengan parameter variabel independen adalah X_poly, dan variabel dependennya adalah y. # Visualisasi hasil regresi sederhana plt.scatter(X, y, color ``=`` ``'red'``) plt.plot(X, lin_reg.predict(X), color ``=`` ``'blue'``) plt.title(``'Sesuai atau tidak (Linear Regression)'``) plt.xlabel(``'Level posisi'``) plt.ylabel(``'Gaji'``) plt.show() Line 24 sampai line 29 adalah perintah untuk visualisasi hasil model regresi sederhana kita. Ingat untuk visualisasi, perintah dari line 24-29 harus dieksekusi bersamaan. Visualisasinya akan nampak sebagai berikut : # Visualisasi hasil regresi polynomial plt.scatter(X, y, color ``=`` ``'red'``) plt.plot(X, lin_reg_2.predict(X_poly), color ``=`` ``'blue'``) plt.title(``'Sesuai atau tidak (Polynomial Regression)'``) plt.xlabel(``'Level posisi'``) plt.ylabel(``'Gaji'``) plt.show() Line 32 sampai line 37 adalah perintah untuk visualisasi hasil model regresi polinomial. Pelru diingat sumbu y nya adalah lin_reg_2.predict(X_poly) . Hasilnya akan tampak sebagai berikut : Bisa dilihat dengan menggunakan fungsi polinomial hasilnya cukup baik. Namun tetap saja masih kurang cukup fit , di mana masih ada jarak antara model dengan data. Solusinya adalah pada line 18 kita ubah degree nya dari 2 menjadi 4. Eksekusi line 18 sampai line 21. Kemudian eksekusi line 32 sampai line 37. Maka visualisasi yang baru akan tampak sebagai berikut : # Memprediksi hasil dengan regresi sederhana lin_reg.predict(``6.5``) Line 40 adalah perintah untuk melihat dengan model regresi sederhana yang sudah dibuat, berapa gaji yang layak untuk tingkat level 6.5? Maka cukup ganti parameter X di lin_reg.predict(X) dengan angka 6.5. Jika dieksekusi, hasilnya adalah 330378.78 dollar/tahun. Tentunya prediksi dari regresi sederhana terlalu tinggi (terlihat juga di plot visualisasinya). Kita tidak menginginkan gaji yang terlalu tinggi yang merupakan hasil dari model regresi sederhana yang buruk kali ini. # Memprediksi hasil dengan regresi polynomial lin_reg_2.predict(poly_reg.fit_transform(``6.5``)) Line 43 adalah perintah untuk melihat prediksi gaji dengan model regresi polinomial. Perlu diperhatikan bahwa parameter X diganti dengan poly_reg.fit_transform(6.5) dan bukan X_poly. Karena kita ingin mengisi angka 6.5 sebagai parameter X. Sementara X_poky adalah hasil dari definisi fungsi poly_reg.fit_transform(X). Ketika dieksekusi maka hasilnya adalah 158862.45 dollar/tahun. Prediksi yang cukup baik, dengan model yang fit. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Contoh kasus dengan penghitungan sklearn"},{"location":"eliminasi gauss (komnum)/","text":"Eliminasi Gauss Jordan \u00b6 \u200b Eliminasi Gauss adalah suatu metode untuk mengoperasikan nilai-nilai di dalam matriks sehingga menjadi matriks yang lebih sederhana lagi. Dengan melakukan operasi baris sehingga matriks tersebut menjadi matriks yang baris. Ini dapat digunakan sebagai salah satu metode penyelesaian persamaan linear dengan menggunakan matriks. Caranya dengan mengubah persamaan linear tersebut ke dalam matriks teraugmentasi dan mengoperasikannya. Setelah menjadi matriks baris, lakukan substitusi balik untuk mendapatkan nilai dari variabel-variabel tersebut. \u200b Metode Eliminasi Gauss Jordan merupakan pengembangan metode eliminasi gauss, hanya saja augmented matrik , pada sebelah kiri dirubah menjadi matrik diagonal. Algoritma Gauss Jordan \u00b6 \u00b6 Listing Program \u00b6 import numpy as np #Definisi Matrix A = [] B = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) A . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) B . append ( h ) Matrix = np . array ( A , float ) Hasil = np . array ( B , float ) n = len ( Matrix ) #Eliminasi Gauss for k in range ( 0 , n - 1 ): for i in range ( k + 1 , n ): if Matrix [ i , k ] != 0 : lam = Matrix [ i , k ] / Matrix [ k , k ] Matrix [ i , k : n ] = Matrix [ i , k : n ] - ( Matrix [ k , k : n ] * lam ) Hasil [ i ] = Hasil [ i ] - ( Hasil [ k ] * lam ) print ( \"Matrix A : \" , ' \\n ' , Matrix ) #Subtitution x = np . zeros ( n , float ) for m in range ( n - 1 , - 1 , - 1 ): x [ m ] = ( Hasil [ m ] - np . dot ( Matrix [ m , m + 1 : n ], x [ m + 1 : n ])) / Matrix [ m , m ] print ( 'Nilai X ' , m + 1 , '=' , x [ m ]) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Nilai: 1 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Nilai: 4 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Hasil: 12 Masukkan Hasil: 3 Masukkan Hasil: -4 Matrix A : [[ 2. -2. 5. ] [ 0. 6. -0.5 ] [ 0. 0. -7.25]] Nilai X 3 = 3.2413793103448274 Nilai X 2 = -0.2298850574712644 Nilai X 1 = -2.333333333333332 jadi panjang Matrix yang dibuat dalam Program Diatas adalah 3 variabel. |2 -2 5| |12| |1 5 2|=| 3 | |4 5 2| |-4| pivot yang dibentuk adalah a1.1,a2.2,dan a3.3 sehingga semua angka yang ada dibawah pivot akan dikonversikan menjadi nol sesuai hasil program dan hasil dari persamaan diatas menghasilkan x1=-2.333333333, x2=-0.22988505 dan x3=3.2413793 Eliminasi Gauss Jacobi \u00b6 Metode IterasiJacobi merupakan salah satu bidang analisis numerik yang digunakan untuk menyelesaikan permasalahan Persamaan Linier dan sering dijumpai dalam berbagai disiplin ilmu. Metode Iterasi Jacobi merupakan salah satu metode tak langsung, yaitu bermula dari suatu hampiran penyelesaian awal dan kemudian berusaha memperbaiki hampiran dalam tak berhingga namun langkah konvergen. Metode Iterasi Jacobi ini digunakan untuk menyelesaikan persamaan Linier berukuran besar dan proporsi koefisien nolnya besar. Metode ini ditemukan oleh Matematikawan yang berasal dari Jerman,Carl,Gustav,Jacobi. Penemuan ini diperkirakan pada tahun 1800-an. Listing Program \u00b6 from pprint import pprint from numpy import array , zeros , diag , diagflat , dot import numpy as np def jacobi ( A , b , N = 25 , x = None ): #Membuat iniial guess if x is None : x = zeros ( len ( A [ 0 ])) #Membuat vektor dari elemen matrix A D = diag ( A ) R = A - diagflat ( D ) #Iterasi for i in range ( N ): x = ( b - dot ( R , x )) / D return x Mat1 = [] Mat2 = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) Mat1 . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) Mat2 . append ( h ) A = array ( Mat1 , float ) b = array ( Mat2 , float ) x = len ( Mat1 ) guess = np . zeros ( x , float ) sol = jacobi ( A , b , N = 25 , x = guess ) print ( \"A:\" ) pprint ( A ) print ( \"b:\" ) pprint ( b ) print ( \"x:\" ) pprint ( sol ) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 3 Masukkan Nilai: 1 Masukkan Nilai: -1 Masukkan Nilai: 4 Masukkan Nilai: 7 Masukkan Nilai: -3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Hasil: 5 Masukkan Hasil: 20 Masukkan Hasil: 10 A: array([[ 3., 1., -1.], [ 4., 7., -3.], [ 2., -2., 5.]]) b: array([ 5., 20., 10.]) x: array([1.50602413, 3.13253016, 2.6506024 ]) Program Gauss Seidel \u00b6 Listing Program \u00b6 def seidel ( a , x , b ): #Mencari Panjang Matrix n = len ( a ) for j in range ( 0 , n ): d = b [ j ] #Menghitung xi, yi, zi for i in range ( 0 , n ): if ( j != i ): d -= a [ j ][ i ] * x [ i ] x [ j ] = d / a [ j ][ j ] #Solusi return x m = int ( input ( \"Masukkan Panjang Matrix: \" )) a = [] b = [] for k in range ( m ): mat1 = [] for i in range ( m ): l = float ( input ( \"Masukkan a\" + str ( k + 1 ) + \",\" + str ( i + 1 ) + \": \" )) mat1 . append ( l ) h = float ( input ( \"Masukkan Hasil: \" )) b . append ( h ) a . append ( mat1 ) n = 3 x = [ 0 , 0 , 0 ] print ( x ) for i in range ( 0 , 100 ): x = seidel ( a , x , b ) print ( x ) Output: Masukkan Panjang Matrix: 3 Masukkan a1,1: 4 Masukkan a1,2: -1 Masukkan a1,3: 1 Masukkan Hasil: 7 Masukkan a2,1: 4 Masukkan a2,2: -8 Masukkan a2,3: 1 Masukkan Hasil: -21 Masukkan a3,1: -2 Masukkan a3,2: 1 Masukkan a3,3: 5 Masukkan Hasil: 15 [0, 0, 0] [1.75, 3.5, 3.0] [1.875, 3.9375, 2.9625] [1.99375, 3.9921875, 2.9990625] [1.99828125, 3.9990234375, 2.9995078125] [1.99987890625, 3.9998779296875, 2.9999759765625003] [1.99997548828125, 3.9999847412109375, 2.999993247070312] [1.9999978735351562, 3.9999980926513667, 2.999999530883789] [1.9999996404418945, 3.9999997615814205, 2.9999999038604734] [1.9999999644302369, 3.9999999701976776, 2.9999999917325595] [1.9999999946162794, 3.9999999962747097, 2.99999999859157] [1.9999999994207849, 3.9999999995343387, 2.9999999998614464] [1.9999999999182232, 3.999999999941793, 2.999999999978931] [1.9999999999907154, 3.999999999992724, 2.9999999999977414] [1.9999999999987457, 3.9999999999990905, 2.9999999999996803] [1.9999999999998526, 3.9999999999998863, 2.9999999999999636] [1.9999999999999807, 3.999999999999986, 2.999999999999995] [1.9999999999999978, 3.9999999999999987, 2.9999999999999996] [1.9999999999999996, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] Dari soal diatas persamaan yang dipilih adalah 4x-y+z=7, 4x-8y+z=-21 dan -2x+y+5z=15. Iterasi yang digunakan sebanyak 100 iterasi sehingga dapat menghasilkan x=2,y=4 dan z=3. Sekian dan Terima Kasih","title":"Eliminasi Gauss"},{"location":"eliminasi gauss (komnum)/#eliminasi-gauss-jordan","text":"\u200b Eliminasi Gauss adalah suatu metode untuk mengoperasikan nilai-nilai di dalam matriks sehingga menjadi matriks yang lebih sederhana lagi. Dengan melakukan operasi baris sehingga matriks tersebut menjadi matriks yang baris. Ini dapat digunakan sebagai salah satu metode penyelesaian persamaan linear dengan menggunakan matriks. Caranya dengan mengubah persamaan linear tersebut ke dalam matriks teraugmentasi dan mengoperasikannya. Setelah menjadi matriks baris, lakukan substitusi balik untuk mendapatkan nilai dari variabel-variabel tersebut. \u200b Metode Eliminasi Gauss Jordan merupakan pengembangan metode eliminasi gauss, hanya saja augmented matrik , pada sebelah kiri dirubah menjadi matrik diagonal.","title":"Eliminasi Gauss Jordan"},{"location":"eliminasi gauss (komnum)/#algoritma-gauss-jordan","text":"","title":"Algoritma Gauss Jordan"},{"location":"eliminasi gauss (komnum)/#listing-program","text":"import numpy as np #Definisi Matrix A = [] B = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) A . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) B . append ( h ) Matrix = np . array ( A , float ) Hasil = np . array ( B , float ) n = len ( Matrix ) #Eliminasi Gauss for k in range ( 0 , n - 1 ): for i in range ( k + 1 , n ): if Matrix [ i , k ] != 0 : lam = Matrix [ i , k ] / Matrix [ k , k ] Matrix [ i , k : n ] = Matrix [ i , k : n ] - ( Matrix [ k , k : n ] * lam ) Hasil [ i ] = Hasil [ i ] - ( Hasil [ k ] * lam ) print ( \"Matrix A : \" , ' \\n ' , Matrix ) #Subtitution x = np . zeros ( n , float ) for m in range ( n - 1 , - 1 , - 1 ): x [ m ] = ( Hasil [ m ] - np . dot ( Matrix [ m , m + 1 : n ], x [ m + 1 : n ])) / Matrix [ m , m ] print ( 'Nilai X ' , m + 1 , '=' , x [ m ]) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Nilai: 1 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Nilai: 4 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Hasil: 12 Masukkan Hasil: 3 Masukkan Hasil: -4 Matrix A : [[ 2. -2. 5. ] [ 0. 6. -0.5 ] [ 0. 0. -7.25]] Nilai X 3 = 3.2413793103448274 Nilai X 2 = -0.2298850574712644 Nilai X 1 = -2.333333333333332 jadi panjang Matrix yang dibuat dalam Program Diatas adalah 3 variabel. |2 -2 5| |12| |1 5 2|=| 3 | |4 5 2| |-4| pivot yang dibentuk adalah a1.1,a2.2,dan a3.3 sehingga semua angka yang ada dibawah pivot akan dikonversikan menjadi nol sesuai hasil program dan hasil dari persamaan diatas menghasilkan x1=-2.333333333, x2=-0.22988505 dan x3=3.2413793","title":"Listing Program"},{"location":"eliminasi gauss (komnum)/#eliminasi-gauss-jacobi","text":"Metode IterasiJacobi merupakan salah satu bidang analisis numerik yang digunakan untuk menyelesaikan permasalahan Persamaan Linier dan sering dijumpai dalam berbagai disiplin ilmu. Metode Iterasi Jacobi merupakan salah satu metode tak langsung, yaitu bermula dari suatu hampiran penyelesaian awal dan kemudian berusaha memperbaiki hampiran dalam tak berhingga namun langkah konvergen. Metode Iterasi Jacobi ini digunakan untuk menyelesaikan persamaan Linier berukuran besar dan proporsi koefisien nolnya besar. Metode ini ditemukan oleh Matematikawan yang berasal dari Jerman,Carl,Gustav,Jacobi. Penemuan ini diperkirakan pada tahun 1800-an.","title":"Eliminasi Gauss Jacobi"},{"location":"eliminasi gauss (komnum)/#listing-program_1","text":"from pprint import pprint from numpy import array , zeros , diag , diagflat , dot import numpy as np def jacobi ( A , b , N = 25 , x = None ): #Membuat iniial guess if x is None : x = zeros ( len ( A [ 0 ])) #Membuat vektor dari elemen matrix A D = diag ( A ) R = A - diagflat ( D ) #Iterasi for i in range ( N ): x = ( b - dot ( R , x )) / D return x Mat1 = [] Mat2 = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) Mat1 . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) Mat2 . append ( h ) A = array ( Mat1 , float ) b = array ( Mat2 , float ) x = len ( Mat1 ) guess = np . zeros ( x , float ) sol = jacobi ( A , b , N = 25 , x = guess ) print ( \"A:\" ) pprint ( A ) print ( \"b:\" ) pprint ( b ) print ( \"x:\" ) pprint ( sol ) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 3 Masukkan Nilai: 1 Masukkan Nilai: -1 Masukkan Nilai: 4 Masukkan Nilai: 7 Masukkan Nilai: -3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Hasil: 5 Masukkan Hasil: 20 Masukkan Hasil: 10 A: array([[ 3., 1., -1.], [ 4., 7., -3.], [ 2., -2., 5.]]) b: array([ 5., 20., 10.]) x: array([1.50602413, 3.13253016, 2.6506024 ])","title":"Listing Program"},{"location":"eliminasi gauss (komnum)/#program-gauss-seidel","text":"","title":"Program Gauss Seidel"},{"location":"eliminasi gauss (komnum)/#listing-program_2","text":"def seidel ( a , x , b ): #Mencari Panjang Matrix n = len ( a ) for j in range ( 0 , n ): d = b [ j ] #Menghitung xi, yi, zi for i in range ( 0 , n ): if ( j != i ): d -= a [ j ][ i ] * x [ i ] x [ j ] = d / a [ j ][ j ] #Solusi return x m = int ( input ( \"Masukkan Panjang Matrix: \" )) a = [] b = [] for k in range ( m ): mat1 = [] for i in range ( m ): l = float ( input ( \"Masukkan a\" + str ( k + 1 ) + \",\" + str ( i + 1 ) + \": \" )) mat1 . append ( l ) h = float ( input ( \"Masukkan Hasil: \" )) b . append ( h ) a . append ( mat1 ) n = 3 x = [ 0 , 0 , 0 ] print ( x ) for i in range ( 0 , 100 ): x = seidel ( a , x , b ) print ( x ) Output: Masukkan Panjang Matrix: 3 Masukkan a1,1: 4 Masukkan a1,2: -1 Masukkan a1,3: 1 Masukkan Hasil: 7 Masukkan a2,1: 4 Masukkan a2,2: -8 Masukkan a2,3: 1 Masukkan Hasil: -21 Masukkan a3,1: -2 Masukkan a3,2: 1 Masukkan a3,3: 5 Masukkan Hasil: 15 [0, 0, 0] [1.75, 3.5, 3.0] [1.875, 3.9375, 2.9625] [1.99375, 3.9921875, 2.9990625] [1.99828125, 3.9990234375, 2.9995078125] [1.99987890625, 3.9998779296875, 2.9999759765625003] [1.99997548828125, 3.9999847412109375, 2.999993247070312] [1.9999978735351562, 3.9999980926513667, 2.999999530883789] [1.9999996404418945, 3.9999997615814205, 2.9999999038604734] [1.9999999644302369, 3.9999999701976776, 2.9999999917325595] [1.9999999946162794, 3.9999999962747097, 2.99999999859157] [1.9999999994207849, 3.9999999995343387, 2.9999999998614464] [1.9999999999182232, 3.999999999941793, 2.999999999978931] [1.9999999999907154, 3.999999999992724, 2.9999999999977414] [1.9999999999987457, 3.9999999999990905, 2.9999999999996803] [1.9999999999998526, 3.9999999999998863, 2.9999999999999636] [1.9999999999999807, 3.999999999999986, 2.999999999999995] [1.9999999999999978, 3.9999999999999987, 2.9999999999999996] [1.9999999999999996, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] Dari soal diatas persamaan yang dipilih adalah 4x-y+z=7, 4x-8y+z=-21 dan -2x+y+5z=15. Iterasi yang digunakan sebanyak 100 iterasi sehingga dapat menghasilkan x=2,y=4 dan z=3. Sekian dan Terima Kasih","title":"Listing Program"},{"location":"fuzzy clustering/","text":"fuzzy clustering \u00b6 pengertian fuzzy clustering: \u00b6 Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'serie.legend()ns_4.png) newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"fuzzy clustering"},{"location":"fuzzy clustering/#fuzzy-clustering","text":"","title":"fuzzy clustering"},{"location":"fuzzy clustering/#pengertian-fuzzy-clustering","text":"Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'serie.legend()ns_4.png) newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"pengertian fuzzy clustering:"},{"location":"index2/","text":"Welcome Komputasi Numerik \u00b6 Biodata \u00b6 Nama : Rike Ayu Arista NIM : 180411100088 Mata Kuliah : Komputasi Numerik 4-B Program Studi : Teknik Informatika Fakultas : Teknik Perguruan Tinggi : Universitas Trunojoyo Madura","title":"Home"},{"location":"index2/#welcome-komputasi-numerik","text":"","title":"Welcome Komputasi Numerik"},{"location":"index2/#biodata","text":"Nama : Rike Ayu Arista NIM : 180411100088 Mata Kuliah : Komputasi Numerik 4-B Program Studi : Teknik Informatika Fakultas : Teknik Perguruan Tinggi : Universitas Trunojoyo Madura","title":"Biodata"},{"location":"jrak/","text":"Mengukur Jarak Data \u00b6 Mengukur Jarak Tipe Numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkanSebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaitu v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance \u00b6 Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Manhattan distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ Euclidean distance \u00b6 Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. Average Distance \u00b6 Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,y dalam ruang dimensi n, rata-rata jarak didefinisikan dengan $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Weighted euclidean distance \u00b6 Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ Chord distance \u00b6 Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ $$ dimana | x | {2} adalah L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum_{ i = 1 }^{ n }x_{i}^{2}} $$ Mahalanobis distance \u00b6 Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ Tugas II Mengukur Jarak Data \u00b6 from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt import pandas as pd df = pd . read_csv ( 'data2.csv' , sep = \";\" ) k = df . iloc [ 10 : 17 ] k .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age of patient at time of operation Patient's year of operation Number of positive axillary nodes detected Unnamed: 3 10 34 60 1 1 11 34 61 10 1 12 34 67 7 1 13 34 60 0 1 14 35 64 13 1 15 35 63 0 1 16 36 60 1 1 numerical = [ 0 , 3 ] categorical = [ 1 , 2 , 6 , 7 ] binary = [ 4 , 5 , 8 ] ordinal = [ 1 , 2 ] from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 0 0 0 0 v1-v3 0 0 0 0 0 v2-v3 0 0 0 0 0 v3-v4 0 0 0 0 0 v4-v5 0 0 0 0 0 v5-v6 0 0 0 0 0 Jarak numeric \u00b6 def chordDist ( v1 , v2 , jnis ): jmlh = 0 normv1 = 0 normv2 = 0 for x in range ( len ( jnis )): normv1 = normv1 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) normv2 = normv2 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) jmlh = jmlh + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) * int ( k . values . tolist ()[ v2 ][ jnis [ x ]])) return (( 2 - ( 2 * jmlh / ( normv1 * normv2 ))) ** 0.5 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 1 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 3 , 4 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 1.41 0 0 0 v1-v3 0 1.41 0 0 0 v2-v3 0 1.41 0 0 0 v3-v4 0 1.41 0 0 0 v4-v5 0 1.41 0 0 0 v5-v6 0 1.41 0 0 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"menghitung jarak"},{"location":"jrak/#mengukur-jarak-data","text":"","title":"Mengukur Jarak Data"},{"location":"jrak/#mengukur-jarak-tipe-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkanSebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaitu v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya","title":"Mengukur Jarak Tipe Numerik"},{"location":"jrak/#minkowski-distance","text":"Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$","title":"Minkowski Distance"},{"location":"jrak/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Manhattan distance"},{"location":"jrak/#euclidean-distance","text":"Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini.","title":"Euclidean distance"},{"location":"jrak/#average-distance","text":"Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,y dalam ruang dimensi n, rata-rata jarak didefinisikan dengan $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Average Distance"},{"location":"jrak/#weighted-euclidean-distance","text":"Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$","title":"Weighted euclidean distance"},{"location":"jrak/#chord-distance","text":"Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ $$ dimana | x | {2} adalah L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum_{ i = 1 }^{ n }x_{i}^{2}} $$","title":"Chord distance"},{"location":"jrak/#mahalanobis-distance","text":"Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$","title":"Mahalanobis distance"},{"location":"jrak/#tugas-ii-mengukur-jarak-data","text":"from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt import pandas as pd df = pd . read_csv ( 'data2.csv' , sep = \";\" ) k = df . iloc [ 10 : 17 ] k .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age of patient at time of operation Patient's year of operation Number of positive axillary nodes detected Unnamed: 3 10 34 60 1 1 11 34 61 10 1 12 34 67 7 1 13 34 60 0 1 14 35 64 13 1 15 35 63 0 1 16 36 60 1 1 numerical = [ 0 , 3 ] categorical = [ 1 , 2 , 6 , 7 ] binary = [ 4 , 5 , 8 ] ordinal = [ 1 , 2 ] from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 0 0 0 0 v1-v3 0 0 0 0 0 v2-v3 0 0 0 0 0 v3-v4 0 0 0 0 0 v4-v5 0 0 0 0 0 v5-v6 0 0 0 0 0","title":"Tugas II Mengukur Jarak Data"},{"location":"jrak/#jarak-numeric","text":"def chordDist ( v1 , v2 , jnis ): jmlh = 0 normv1 = 0 normv2 = 0 for x in range ( len ( jnis )): normv1 = normv1 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) normv2 = normv2 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) jmlh = jmlh + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) * int ( k . values . tolist ()[ v2 ][ jnis [ x ]])) return (( 2 - ( 2 * jmlh / ( normv1 * normv2 ))) ** 0.5 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 1 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 3 , 4 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 1.41 0 0 0 v1-v3 0 1.41 0 0 0 v2-v3 0 1.41 0 0 0 v3-v4 0 1.41 0 0 0 v4-v5 0 1.41 0 0 0 v5-v6 0 1.41 0 0 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Jarak numeric"},{"location":"metode euler (komnum)/","text":"Methode Euler \u00b6 \u200b Dalam matematika dan ilmu komputasi , metode Euler (juga disebut metode forward Euler ) adalah prosedur numerik orde pertama untuk menyelesaikan persamaan diferensial biasa (ODE) dengan nilai awal yang diberikan. Ini adalah metode eksplisit paling dasar untuk integrasi numerik persamaan diferensial biasa dan merupakan metode Runge-Kutta paling sederhana. Metode Euler dinamai Leonhard Euler , yang memperlakukannya dalam bukunya Institutionum calculi integralis (diterbitkan 1768-1870). [ 1] \u200b Metode Euler adalah metode urutan pertama, yang berarti bahwa kesalahan lokal (kesalahan per langkah) sebanding dengan kuadrat ukuran langkah, dan kesalahan global (kesalahan pada waktu tertentu) sebanding dengan ukuran langkah. Metode Euler sering berfungsi sebagai dasar untuk membangun metode yang lebih kompleks, misalnya, metode prediktor-korektor . \u200b Persamaan diferensial yang terdiri dari satu variabel bebas dinamakan persamaan diferensial parsial biasa (ODE). sementara itu, persamaan diferensial yang terdiri dari dua atau lebih variabel bebas dinamakan persamaan diferensial parsial Persamaan Diferensial - PDE). (ODE) memiliki bentik umum yaitu: Contoh soal \u00b6 Code Program dengan Python \u00b6 print ( \"f(x,y)=1+x^2\" ) print ( \"yi+1 = y1 + hf(xi+yi)\" ) x1 = float ( input ( \"Masukkan x1= \" )) x2 = float ( input ( \"Masukkan x2= \" )) h = 1.01 - x1 #Langsung saya atur sendiri karena yang dicari f(x,y) nilai x-nya=1.01 n = 4 #jumlah x ada 4 yaitu 1, 1.01, 1.02, 1.03 xi = - 4 hasil = xi y = 0 for i in range ( n ): print ( \"hasil dari y\" + str ( i ) + \"= \" + str ( hasil )) hasil = xi + h * ( 1 + ( x1 + y ) ** 2 ) y += h xi = hasil pada bagian pertama terdapat variable x1 adalah x awal dan x2 merupakan x akhir. karena di soal terdapat nx=3 yaitu x0=1, x1=1,01, x3=1,02 x2=1,03 maka h= xn-x0/n, hasilnya h = 0.01. xi adalah hasil awal yang kemudian akan dimasukkan pada prosess iterasi. Karena rumus eurel adalah y1 = y0 +h(f(x,y)) maka rumus barunya adalah y1=y0+h(1+x^2). variable y digunakan untuk penambahan nilai x agar selalu bertambah 0.01. < script type = \"text/x-mathjax-config\" > MathJax . Hub . Config ({ tex2jax : { inlineMath : [[ '$$' , '$$' ],[ '$' , '$' ]]} }); </ script > < script type = \"text/javascript\" async src = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\" > </ script >","title":"Metode Euler"},{"location":"metode euler (komnum)/#methode-euler","text":"\u200b Dalam matematika dan ilmu komputasi , metode Euler (juga disebut metode forward Euler ) adalah prosedur numerik orde pertama untuk menyelesaikan persamaan diferensial biasa (ODE) dengan nilai awal yang diberikan. Ini adalah metode eksplisit paling dasar untuk integrasi numerik persamaan diferensial biasa dan merupakan metode Runge-Kutta paling sederhana. Metode Euler dinamai Leonhard Euler , yang memperlakukannya dalam bukunya Institutionum calculi integralis (diterbitkan 1768-1870). [ 1] \u200b Metode Euler adalah metode urutan pertama, yang berarti bahwa kesalahan lokal (kesalahan per langkah) sebanding dengan kuadrat ukuran langkah, dan kesalahan global (kesalahan pada waktu tertentu) sebanding dengan ukuran langkah. Metode Euler sering berfungsi sebagai dasar untuk membangun metode yang lebih kompleks, misalnya, metode prediktor-korektor . \u200b Persamaan diferensial yang terdiri dari satu variabel bebas dinamakan persamaan diferensial parsial biasa (ODE). sementara itu, persamaan diferensial yang terdiri dari dua atau lebih variabel bebas dinamakan persamaan diferensial parsial Persamaan Diferensial - PDE). (ODE) memiliki bentik umum yaitu:","title":"Methode Euler"},{"location":"metode euler (komnum)/#contoh-soal","text":"","title":"Contoh soal"},{"location":"metode euler (komnum)/#code-program-dengan-python","text":"print ( \"f(x,y)=1+x^2\" ) print ( \"yi+1 = y1 + hf(xi+yi)\" ) x1 = float ( input ( \"Masukkan x1= \" )) x2 = float ( input ( \"Masukkan x2= \" )) h = 1.01 - x1 #Langsung saya atur sendiri karena yang dicari f(x,y) nilai x-nya=1.01 n = 4 #jumlah x ada 4 yaitu 1, 1.01, 1.02, 1.03 xi = - 4 hasil = xi y = 0 for i in range ( n ): print ( \"hasil dari y\" + str ( i ) + \"= \" + str ( hasil )) hasil = xi + h * ( 1 + ( x1 + y ) ** 2 ) y += h xi = hasil pada bagian pertama terdapat variable x1 adalah x awal dan x2 merupakan x akhir. karena di soal terdapat nx=3 yaitu x0=1, x1=1,01, x3=1,02 x2=1,03 maka h= xn-x0/n, hasilnya h = 0.01. xi adalah hasil awal yang kemudian akan dimasukkan pada prosess iterasi. Karena rumus eurel adalah y1 = y0 +h(f(x,y)) maka rumus barunya adalah y1=y0+h(1+x^2). variable y digunakan untuk penambahan nilai x agar selalu bertambah 0.01. < script type = \"text/x-mathjax-config\" > MathJax . Hub . Config ({ tex2jax : { inlineMath : [[ '$$' , '$$' ],[ '$' , '$' ]]} }); </ script > < script type = \"text/javascript\" async src = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\" > </ script >","title":"Code Program dengan Python"},{"location":"richardson (komnum)/","text":"Richardson Extrapolation \u00b6 Dalam analisis numerik, Richardson Extrapolation adalah metode percepatan urutan, yang digunakan untuk meningkatkan laju konvergensi suatu urutan. Richardson Extrapolation termasuk integrasi Romberg, yang menerapkan ekstrapolasi Richardson pada aturan trapesium, dan algoritma Bulirsch-Stoer untuk menyelesaikan persamaan diferensial biasa. Teori \u00b6 Dalam rumus : ( f (x + h) - f (x - h) ) / (2 h) untuk nilai h yang sangat kecil, dua fungsi evaluasi f (x + h) dan f (x - h) akan menjadi kira-kira sama, dan oleh karena itu pembatalan subtraktif akan terjadi. Oleh karena itu, tidak disarankan untuk menggunakan nilai h yang semakin kecil. Kita dapat mencoba untuk memperkirakan nilai tepat e dengan perkiraan a(h) . Dalam hal ini, e adalah turunan dari f (1) (x) dan perkiraannya adalah ( h ) = (f (x + h) - f (x - h)) / (2 h) . Misalkan sekarang bahwa kesalahan aproksimasi didefinisikan oleh serangkaian bentuk Taylor : e = a(h) + K h n + o(h n ) Apabila menggunakan h / 2 : e = a(h/2) + K (h/2)n + o((h/2)n) = a(h/2) + K/2n h n + o(h n ) Mengalikan kedua ekspresi ini dengan 2 n dan mengurangi hasil persamaan pertama 2n e \u2212 e = 2na(h/2) \u2212 a(h) + K/2n h n \u2212 K h n + o(h n ) Perhatikan bahwa istilah h n dibatalkan dan kita dibiarkan dengan (2n \u2212 1)e = 2na(h/2) \u2212 a(h) + o(h n ) Jika kita melihat seri Taylor lengkap untuk rumus perbedaan-terpusat yang terpusat, kita perhatikan bahwa istilah kesalahannya dalam bentuk Knh n . Dapat kita tulis dengan : K1 = \u22121/6 f(3)(x)h 2 , etc. Contoh Program \u00b6 from math import * def zeros ( n , m ): Z = [] for i in range ( n ): Z . append ([ 0 ] * m ) return Z def D ( Func , a , h ): return ( Func ( a + h ) - Func ( a - h )) / ( 2 * h ) def Richardson_dif ( func , a ): '''Richardson extrapolation method for numerical calculation of first derivative ''' k = 9 L = zeros ( k , k ) for I in range ( k ): L [ I ][ 0 ] = D ( func , a , 1 / ( 2 ** ( I + 1 ))) for j in range ( 1 , k ): for i in range ( k - j ): L [ i ][ j ] = (( 4 ** ( j )) * L [ i + 1 ][ j - 1 ] - L [ i ][ j - 1 ]) / ( 4 ** ( j ) - 1 ) return L [ 0 ][ k - 1 ] print ( '>>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<<' ) print ( \"=======================================================================\" ) print ( 'f = -0.1*x**4-0.15*x**3-0.5*x**2-0.25*x+1.2 dengan x = 0.5' ) print ( \"=======================================================================\" ) print ( ' %04.20f ' % Richardson_dif ( lambda x : - 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 , 0.5 )) print ( \"=======================================================================\" ) print ( 'diff(2**cos(pi+sin(x)) dengan x = pi/2 adalah = %04.20f ' % Richardson_dif ( lambda x : 2 ** cos ( pi + sin ( x )), pi / 3 )) Hasil Running \u00b6 >>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<< ======================================================================= f = - 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 dengan x = 0.5 ======================================================================= - 0.91250000000000530687 ======================================================================= diff ( 2 ** cos ( pi + sin ( x )) dengan x = pi / 2 adalah = 0.16849558398154249050 >>>","title":"Richardson Extrapolation"},{"location":"richardson (komnum)/#richardson-extrapolation","text":"Dalam analisis numerik, Richardson Extrapolation adalah metode percepatan urutan, yang digunakan untuk meningkatkan laju konvergensi suatu urutan. Richardson Extrapolation termasuk integrasi Romberg, yang menerapkan ekstrapolasi Richardson pada aturan trapesium, dan algoritma Bulirsch-Stoer untuk menyelesaikan persamaan diferensial biasa.","title":"Richardson Extrapolation"},{"location":"richardson (komnum)/#teori","text":"Dalam rumus : ( f (x + h) - f (x - h) ) / (2 h) untuk nilai h yang sangat kecil, dua fungsi evaluasi f (x + h) dan f (x - h) akan menjadi kira-kira sama, dan oleh karena itu pembatalan subtraktif akan terjadi. Oleh karena itu, tidak disarankan untuk menggunakan nilai h yang semakin kecil. Kita dapat mencoba untuk memperkirakan nilai tepat e dengan perkiraan a(h) . Dalam hal ini, e adalah turunan dari f (1) (x) dan perkiraannya adalah ( h ) = (f (x + h) - f (x - h)) / (2 h) . Misalkan sekarang bahwa kesalahan aproksimasi didefinisikan oleh serangkaian bentuk Taylor : e = a(h) + K h n + o(h n ) Apabila menggunakan h / 2 : e = a(h/2) + K (h/2)n + o((h/2)n) = a(h/2) + K/2n h n + o(h n ) Mengalikan kedua ekspresi ini dengan 2 n dan mengurangi hasil persamaan pertama 2n e \u2212 e = 2na(h/2) \u2212 a(h) + K/2n h n \u2212 K h n + o(h n ) Perhatikan bahwa istilah h n dibatalkan dan kita dibiarkan dengan (2n \u2212 1)e = 2na(h/2) \u2212 a(h) + o(h n ) Jika kita melihat seri Taylor lengkap untuk rumus perbedaan-terpusat yang terpusat, kita perhatikan bahwa istilah kesalahannya dalam bentuk Knh n . Dapat kita tulis dengan : K1 = \u22121/6 f(3)(x)h 2 , etc.","title":"Teori"},{"location":"richardson (komnum)/#contoh-program","text":"from math import * def zeros ( n , m ): Z = [] for i in range ( n ): Z . append ([ 0 ] * m ) return Z def D ( Func , a , h ): return ( Func ( a + h ) - Func ( a - h )) / ( 2 * h ) def Richardson_dif ( func , a ): '''Richardson extrapolation method for numerical calculation of first derivative ''' k = 9 L = zeros ( k , k ) for I in range ( k ): L [ I ][ 0 ] = D ( func , a , 1 / ( 2 ** ( I + 1 ))) for j in range ( 1 , k ): for i in range ( k - j ): L [ i ][ j ] = (( 4 ** ( j )) * L [ i + 1 ][ j - 1 ] - L [ i ][ j - 1 ]) / ( 4 ** ( j ) - 1 ) return L [ 0 ][ k - 1 ] print ( '>>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<<' ) print ( \"=======================================================================\" ) print ( 'f = -0.1*x**4-0.15*x**3-0.5*x**2-0.25*x+1.2 dengan x = 0.5' ) print ( \"=======================================================================\" ) print ( ' %04.20f ' % Richardson_dif ( lambda x : - 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 , 0.5 )) print ( \"=======================================================================\" ) print ( 'diff(2**cos(pi+sin(x)) dengan x = pi/2 adalah = %04.20f ' % Richardson_dif ( lambda x : 2 ** cos ( pi + sin ( x )), pi / 3 ))","title":"Contoh Program"},{"location":"richardson (komnum)/#hasil-running","text":">>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<< ======================================================================= f = - 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 dengan x = 0.5 ======================================================================= - 0.91250000000000530687 ======================================================================= diff ( 2 ** cos ( pi + sin ( x )) dengan x = pi / 2 adalah = 0.16849558398154249050 >>>","title":"Hasil Running"},{"location":"tugas1/","text":"Mean, Modus dan Median \u00b6 Rumus Mean (Rata-rata) Data Kelompok \u00b6 Untuk dapat menentukan mean atau rata rata dari data kelompok maka kita perlu menjumlahkan semua data kemudian membaginya dengan banyaknya data tersebut.namun, karena penyajian data kelompok tersebut diberikan dalam bentuk yang berbeda, maka rumus untuk mencari nilai mean (rata rata) untuk data kelompok itu terlihat sedikit berbeda dengan cara mencari nilai mean (rata rata) pada data tunggal. Rumus mean data kelompok dinyatakan dengan persamaan seperti di bawah. $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Rumus Median Data Kelompok \u00b6 Median ialah data tengah setelah diurutkan. Pada data tunggal, nilai median tersebut dapat dicari dengan mengurutkan datanya terlebih dahulu kemudian mencari data yang terletak tepat di tengahnya.cara ini Hampir sama dengan cara mencari median pada data tunggal, nilai median pada data kelompok juga merupakan nilai tengah dari suatu kumpulan data. Karena bentuk penyajian datanya disajikan dalam bentuk kelompok,maka datanya tidak dapat diurutkan seperti pada data tunggal. Dengan demikian, agar dapat mencari nilai median dari suatu data kelompok diperlukan sebuah rumus. Rumus median data kelompok ialah sebagai berikut. $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Rumus Modus Data Kelompok \u00b6 Modus ialah nilai data yang paling sering muncul atau data yang memiliki nilai frekuensi paling tinggi.untuk mencari nilai modus pada data tunggal sangat mudah,yaitu dengan Cara mencari nilai data dengan frekuensi paling banyak.namun untuk mencari mencari nilai modus pada data kelompok tidak lah semudah kita mencari nilai modus pada data tunggal. Hal ini dikarenakan bentuk penyajian data kelompok yang disajikan dalam sebuah rentang kelas. Sehingga, nilai modus data kelompok tidak mudah untuk langsung didapatkan dan untuk menemukan nilai modus dari data kelompok maka kita perlu menggunakan sebuah rumus. Rumus modus data kelompok dapat dilihat seperti persamaan di bawah ini. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Variansi dan Standar Deviasi \u00b6 Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan N,x1,x2,...,xN, untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$ Skewness \u00b6 Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ Tugas import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Mean, Modus dan Median"},{"location":"tugas1/#mean-modus-dan-median","text":"","title":"Mean, Modus dan Median"},{"location":"tugas1/#rumus-mean-rata-rata-data-kelompok","text":"Untuk dapat menentukan mean atau rata rata dari data kelompok maka kita perlu menjumlahkan semua data kemudian membaginya dengan banyaknya data tersebut.namun, karena penyajian data kelompok tersebut diberikan dalam bentuk yang berbeda, maka rumus untuk mencari nilai mean (rata rata) untuk data kelompok itu terlihat sedikit berbeda dengan cara mencari nilai mean (rata rata) pada data tunggal. Rumus mean data kelompok dinyatakan dengan persamaan seperti di bawah. $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$","title":"Rumus Mean (Rata-rata) Data Kelompok"},{"location":"tugas1/#rumus-median-data-kelompok","text":"Median ialah data tengah setelah diurutkan. Pada data tunggal, nilai median tersebut dapat dicari dengan mengurutkan datanya terlebih dahulu kemudian mencari data yang terletak tepat di tengahnya.cara ini Hampir sama dengan cara mencari median pada data tunggal, nilai median pada data kelompok juga merupakan nilai tengah dari suatu kumpulan data. Karena bentuk penyajian datanya disajikan dalam bentuk kelompok,maka datanya tidak dapat diurutkan seperti pada data tunggal. Dengan demikian, agar dapat mencari nilai median dari suatu data kelompok diperlukan sebuah rumus. Rumus median data kelompok ialah sebagai berikut. $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$","title":"Rumus Median Data Kelompok"},{"location":"tugas1/#rumus-modus-data-kelompok","text":"Modus ialah nilai data yang paling sering muncul atau data yang memiliki nilai frekuensi paling tinggi.untuk mencari nilai modus pada data tunggal sangat mudah,yaitu dengan Cara mencari nilai data dengan frekuensi paling banyak.namun untuk mencari mencari nilai modus pada data kelompok tidak lah semudah kita mencari nilai modus pada data tunggal. Hal ini dikarenakan bentuk penyajian data kelompok yang disajikan dalam sebuah rentang kelas. Sehingga, nilai modus data kelompok tidak mudah untuk langsung didapatkan dan untuk menemukan nilai modus dari data kelompok maka kita perlu menggunakan sebuah rumus. Rumus modus data kelompok dapat dilihat seperti persamaan di bawah ini. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$","title":"Rumus Modus Data Kelompok"},{"location":"tugas1/#variansi-dan-standar-deviasi","text":"Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan N,x1,x2,...,xN, untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$","title":"Variansi dan Standar Deviasi"},{"location":"tugas1/#skewness","text":"Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ Tugas import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Skewness"},{"location":"tugas1komnum/","text":"Welcome di Komputasi Numerik \u00b6 Kesalahan dalam Perhitungan Numerik (Error) \u00b6 Kesalahan \u00b6 Dalam Analisis Numerik kita dapat mengkarakterisasi kesalahan dalam pengukuran dan perhitungan sehubungan dengan keakuratan dan ketepatannya Hubungan antara hasil yang tepat dan perkiraan dapat dirumuskan sebagai : \u200b nilai sebenarnya = aproksimasi + kesalahan ^-^ kesalahan absolut atau benar (Et) : \u200b Et= nilai sebenarnya - perkiraan ^-^ kesalahan relatif ( \u03b5t\u03b5t) : \u200b \u03b5t= nilai sebenarnya - perkiraannilai asli ada beberapa macam kesalahan yaitu : A. Kesalahan pembulatan terjadi karena komputer tidak dapat mewakili jumlah secara tepat. Ada dua sisi utama kesalahan pembulatan sering terlibat dengan perhitungan numerik. \u200b a. Komputer memiliki batas ukuran dan presisi pada angka yang dapat mereka simpan dan hitung. \u200b b. Perhitungan numerik tertentu sangat sensitif terhadap kesalahan pembulatan. Ini bisa dari struktur matematika perhitungan serta bagaimana komputer melakukan operasi. B. Kesalahan pemotongan muncul ketika Anda menggunakan perkiraan menggantikan ekspresi yang tepat dalam prosedur matematika. Salah satu contoh kesalahan pemotongan yang terbaik (dan sering digunakan) adalah pendekatan Taylor Series dari suatu fungsi. DEFINISI MACLAURIN \u00b6 Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret TaylorDefinisi. Berikut algoritma dari maclaurin \u00b6 Dengan algoritma diatas kita dapat menyerderhanakannya sebagai berikut: berikut contoh implementai dari maclaurin f(x)= e 2x $$ f(x)\u22481+2x \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ sekarang kita masukan misal x=0 $$ f(0)\u22481+2(0) \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ jadi ketika x =0 maka hasil akan tetap 1 mekipun banyak suku dan literasi Listing Program \u00b6 membuat program supaya dapaat mengekspansi bilangan e^2x dengan nilai x=4 hingga nilai menjadi kurang dari 0,001 bisa dengan listing program sebagai berikut. import math coba = 1 a = 0 b = 1 x = int ( input ( \"masukkan x = \" )) while coba > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 2 ** i ) * x ** i / math . factorial ( i ) for j in range ( b ): f_y += ( 2 ** j ) * x ** j / math . factorial ( j ) print ( \"suku ke \" , a , \"=\" , f_x ) print ( \"suku ke \" , b , \"=\" , f_y ) coba = f_y - f_x a += 1 b += 1 print ( \"selisih sukunya = \" , coba ) output: masukkan x = 1 suku ke 0 = 0 suku ke 1 = 1.0 selisih sukunya = 1.0 suku ke 1 = 1.0 suku ke 2 = 3.0 selisih sukunya = 2.0 suku ke 2 = 3.0 suku ke 3 = 5.0 selisih sukunya = 2.0 suku ke 3 = 5.0 suku ke 4 = 6.333333333333333 selisih sukunya = 1.333333333333333 suku ke 4 = 6.333333333333333 suku ke 5 = 7.0 selisih sukunya = 0.666666666666667 suku ke 5 = 7.0 suku ke 6 = 7.266666666666667 selisih sukunya = 0.2666666666666666 suku ke 6 = 7.266666666666667 suku ke 7 = 7.355555555555555 selisih sukunya = 0.08888888888888857 suku ke 7 = 7.355555555555555 suku ke 8 = 7.3809523809523805 selisih sukunya = 0.025396825396825307 suku ke 8 = 7.3809523809523805 suku ke 9 = 7.387301587301587 selisih sukunya = 0.006349206349206327 suku ke 9 = 7.387301587301587 suku ke 10 = 7.3887125220458545 selisih sukunya = 0.0014109347442676778 suku ke 10 = 7.3887125220458545 suku ke 11 = 7.388994708994708 selisih sukunya = 0.0002821869488531803 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Error In Numerical Computation"},{"location":"tugas1komnum/#welcome-di-komputasi-numerik","text":"","title":"Welcome di Komputasi Numerik"},{"location":"tugas1komnum/#kesalahan-dalam-perhitungan-numerik-error","text":"","title":"Kesalahan dalam Perhitungan Numerik (Error)"},{"location":"tugas1komnum/#kesalahan","text":"Dalam Analisis Numerik kita dapat mengkarakterisasi kesalahan dalam pengukuran dan perhitungan sehubungan dengan keakuratan dan ketepatannya Hubungan antara hasil yang tepat dan perkiraan dapat dirumuskan sebagai : \u200b nilai sebenarnya = aproksimasi + kesalahan ^-^ kesalahan absolut atau benar (Et) : \u200b Et= nilai sebenarnya - perkiraan ^-^ kesalahan relatif ( \u03b5t\u03b5t) : \u200b \u03b5t= nilai sebenarnya - perkiraannilai asli ada beberapa macam kesalahan yaitu : A. Kesalahan pembulatan terjadi karena komputer tidak dapat mewakili jumlah secara tepat. Ada dua sisi utama kesalahan pembulatan sering terlibat dengan perhitungan numerik. \u200b a. Komputer memiliki batas ukuran dan presisi pada angka yang dapat mereka simpan dan hitung. \u200b b. Perhitungan numerik tertentu sangat sensitif terhadap kesalahan pembulatan. Ini bisa dari struktur matematika perhitungan serta bagaimana komputer melakukan operasi. B. Kesalahan pemotongan muncul ketika Anda menggunakan perkiraan menggantikan ekspresi yang tepat dalam prosedur matematika. Salah satu contoh kesalahan pemotongan yang terbaik (dan sering digunakan) adalah pendekatan Taylor Series dari suatu fungsi.","title":"Kesalahan"},{"location":"tugas1komnum/#definisi-maclaurin","text":"Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret TaylorDefinisi.","title":"DEFINISI MACLAURIN"},{"location":"tugas1komnum/#berikut-algoritma-dari-maclaurin","text":"Dengan algoritma diatas kita dapat menyerderhanakannya sebagai berikut: berikut contoh implementai dari maclaurin f(x)= e 2x $$ f(x)\u22481+2x \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ sekarang kita masukan misal x=0 $$ f(0)\u22481+2(0) \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ jadi ketika x =0 maka hasil akan tetap 1 mekipun banyak suku dan literasi","title":"Berikut algoritma dari maclaurin"},{"location":"tugas1komnum/#listing-program","text":"membuat program supaya dapaat mengekspansi bilangan e^2x dengan nilai x=4 hingga nilai menjadi kurang dari 0,001 bisa dengan listing program sebagai berikut. import math coba = 1 a = 0 b = 1 x = int ( input ( \"masukkan x = \" )) while coba > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 2 ** i ) * x ** i / math . factorial ( i ) for j in range ( b ): f_y += ( 2 ** j ) * x ** j / math . factorial ( j ) print ( \"suku ke \" , a , \"=\" , f_x ) print ( \"suku ke \" , b , \"=\" , f_y ) coba = f_y - f_x a += 1 b += 1 print ( \"selisih sukunya = \" , coba ) output: masukkan x = 1 suku ke 0 = 0 suku ke 1 = 1.0 selisih sukunya = 1.0 suku ke 1 = 1.0 suku ke 2 = 3.0 selisih sukunya = 2.0 suku ke 2 = 3.0 suku ke 3 = 5.0 selisih sukunya = 2.0 suku ke 3 = 5.0 suku ke 4 = 6.333333333333333 selisih sukunya = 1.333333333333333 suku ke 4 = 6.333333333333333 suku ke 5 = 7.0 selisih sukunya = 0.666666666666667 suku ke 5 = 7.0 suku ke 6 = 7.266666666666667 selisih sukunya = 0.2666666666666666 suku ke 6 = 7.266666666666667 suku ke 7 = 7.355555555555555 selisih sukunya = 0.08888888888888857 suku ke 7 = 7.355555555555555 suku ke 8 = 7.3809523809523805 selisih sukunya = 0.025396825396825307 suku ke 8 = 7.3809523809523805 suku ke 9 = 7.387301587301587 selisih sukunya = 0.006349206349206327 suku ke 9 = 7.387301587301587 suku ke 10 = 7.3887125220458545 selisih sukunya = 0.0014109347442676778 suku ke 10 = 7.3887125220458545 suku ke 11 = 7.388994708994708 selisih sukunya = 0.0002821869488531803 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Listing Program"},{"location":"tugas1pendat/","text":"Mean, Modus dan Median \u00b6 Rumus Mean (Rata-rata) Data Kelompok \u00b6 Untuk dapat menentukan mean atau rata rata dari data kelompok maka kita perlu menjumlahkan semua data kemudian membaginya dengan banyaknya data tersebut.namun, karena penyajian data kelompok tersebut diberikan dalam bentuk yang berbeda, maka rumus untuk mencari nilai mean (rata rata) untuk data kelompok itu terlihat sedikit berbeda dengan cara mencari nilai mean (rata rata) pada data tunggal. Rumus mean data kelompok dinyatakan dengan persamaan seperti di bawah. $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Rumus Median Data Kelompok \u00b6 Median ialah data tengah setelah diurutkan. Pada data tunggal, nilai median tersebut dapat dicari dengan mengurutkan datanya terlebih dahulu kemudian mencari data yang terletak tepat di tengahnya.cara ini Hampir sama dengan cara mencari median pada data tunggal, nilai median pada data kelompok juga merupakan nilai tengah dari suatu kumpulan data. Karena bentuk penyajian datanya disajikan dalam bentuk kelompok,maka datanya tidak dapat diurutkan seperti pada data tunggal. Dengan demikian, agar dapat mencari nilai median dari suatu data kelompok diperlukan sebuah rumus. Rumus median data kelompok ialah sebagai berikut. $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Rumus Modus Data Kelompok \u00b6 Modus ialah nilai data yang paling sering muncul atau data yang memiliki nilai frekuensi paling tinggi.untuk mencari nilai modus pada data tunggal sangat mudah,yaitu dengan Cara mencari nilai data dengan frekuensi paling banyak.namun untuk mencari mencari nilai modus pada data kelompok tidak lah semudah kita mencari nilai modus pada data tunggal. Hal ini dikarenakan bentuk penyajian data kelompok yang disajikan dalam sebuah rentang kelas. Sehingga, nilai modus data kelompok tidak mudah untuk langsung didapatkan dan untuk menemukan nilai modus dari data kelompok maka kita perlu menggunakan sebuah rumus. Rumus modus data kelompok dapat dilihat seperti persamaan di bawah ini. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Variansi dan Standar Deviasi \u00b6 Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan N,x1,x2,...,xN, untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$ Skewness \u00b6 Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ Tugas import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Statistik Deskriptif"},{"location":"tugas1pendat/#mean-modus-dan-median","text":"","title":"Mean, Modus dan Median"},{"location":"tugas1pendat/#rumus-mean-rata-rata-data-kelompok","text":"Untuk dapat menentukan mean atau rata rata dari data kelompok maka kita perlu menjumlahkan semua data kemudian membaginya dengan banyaknya data tersebut.namun, karena penyajian data kelompok tersebut diberikan dalam bentuk yang berbeda, maka rumus untuk mencari nilai mean (rata rata) untuk data kelompok itu terlihat sedikit berbeda dengan cara mencari nilai mean (rata rata) pada data tunggal. Rumus mean data kelompok dinyatakan dengan persamaan seperti di bawah. $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$","title":"Rumus Mean (Rata-rata) Data Kelompok"},{"location":"tugas1pendat/#rumus-median-data-kelompok","text":"Median ialah data tengah setelah diurutkan. Pada data tunggal, nilai median tersebut dapat dicari dengan mengurutkan datanya terlebih dahulu kemudian mencari data yang terletak tepat di tengahnya.cara ini Hampir sama dengan cara mencari median pada data tunggal, nilai median pada data kelompok juga merupakan nilai tengah dari suatu kumpulan data. Karena bentuk penyajian datanya disajikan dalam bentuk kelompok,maka datanya tidak dapat diurutkan seperti pada data tunggal. Dengan demikian, agar dapat mencari nilai median dari suatu data kelompok diperlukan sebuah rumus. Rumus median data kelompok ialah sebagai berikut. $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$","title":"Rumus Median Data Kelompok"},{"location":"tugas1pendat/#rumus-modus-data-kelompok","text":"Modus ialah nilai data yang paling sering muncul atau data yang memiliki nilai frekuensi paling tinggi.untuk mencari nilai modus pada data tunggal sangat mudah,yaitu dengan Cara mencari nilai data dengan frekuensi paling banyak.namun untuk mencari mencari nilai modus pada data kelompok tidak lah semudah kita mencari nilai modus pada data tunggal. Hal ini dikarenakan bentuk penyajian data kelompok yang disajikan dalam sebuah rentang kelas. Sehingga, nilai modus data kelompok tidak mudah untuk langsung didapatkan dan untuk menemukan nilai modus dari data kelompok maka kita perlu menggunakan sebuah rumus. Rumus modus data kelompok dapat dilihat seperti persamaan di bawah ini. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$","title":"Rumus Modus Data Kelompok"},{"location":"tugas1pendat/#variansi-dan-standar-deviasi","text":"Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan N,x1,x2,...,xN, untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$","title":"Variansi dan Standar Deviasi"},{"location":"tugas1pendat/#skewness","text":"Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ Tugas import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Skewness"}]}